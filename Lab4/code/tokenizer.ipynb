{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Preprocessing the dataset\n",
    "Prepare the data for finetuning. To do so you have to:\n",
    "1. Use the provided sentencepiece model to tokenize the text.\n",
    "2. Binarize the data using `fairseq-preprocess` command\n",
    "\n",
    "## Tokenizing the reviews\n",
    "\n",
    "In this section we will tokenize the finetuning dataset using sentenpiece tokenizer. We have three splits in our datase: train valid and test sets.\n",
    "\n",
    "In this task you have to use the trained sentencepiece tokenizer (RoBERTa_small_fr/sentencepiece.bpe.model) to tokenize the three files <b>train.review</b>, <b>valid.review</b> and <b>test.review</b> and output the three files <b>train.spm.review</b>, <b>valid.spm.review</b> and <b>test.spm.review</b> containing the tokenized reviews.\n",
    "\n",
    "Documentation: https://github.com/google/sentencepiece#readme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ce livre est tout simplement magique !  il vaut le detour suspense, humour, magi\n",
      "J'ai lu ce livre car dans ma ville, tout le monde s'en sert et le commande. C'es\n",
      "Ce livre explique techniquement et de façon très compréhensible, même pour des n\n"
     ]
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "s = spm.SentencePieceProcessor(model_file='../models/RoBERTa_small_fr/sentencepiece.bpe.model')\n",
    "\n",
    "SPLITS=['train', 'test', 'valid']\n",
    "SENTS=\"review\"\n",
    "DATA_BOOKS = '../data/cls.books/'\n",
    "for split in SPLITS:\n",
    "    with open(DATA_BOOKS+split+'.'+SENTS, 'r') as f:\n",
    "        reviews = f.readlines()\n",
    "        print(reviews[0][:80])\n",
    "        tokenized = [\" \".join(s.encode(review, out_type=str)) for review in reviews]\n",
    "        # tokenize the data using s.encode and a loop(check the documentation)\n",
    "\n",
    "        # It should look something like this :\n",
    "        #▁An ci enne ▁VS ▁Nouvelle ▁version ▁plus\n",
    "\n",
    "    with open(DATA_BOOKS+split+'.spm.'+SENTS, 'w') as f:\n",
    "        for review in reviews:\n",
    "          f.write(\"\\n\".join(review)+'\\n')\n",
    "    \n",
    "    with open(DATA_BOOKS+split+'.spm.'+SENTS, 'w') as f:\n",
    "        f.writelines(\"\\n\".join(tokenized)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▁Ce ▁livre ▁explique ▁technique ment ▁et ▁de ▁façon ▁très ▁com pré hen sible , ▁\n"
     ]
    }
   ],
   "source": [
    "print(tokenized[0][:80])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b>Binarizing/Preprocessing the finetuning dataset</b>\n",
    "\n",
    "In this section, you have to binarize the CLS_Books dataset using the <b>fairseq/fairseq_cli/preprocess.py</b> script:\n",
    "\n",
    "1- Binarize the tokenized reviews and put the output in <b>data/cls-books-bin/input0</b>. Note: Our pretrained model's embedding matrix contains only the embedding of the vocab listed in the dictionary <b>dict.txt</b>. You need to use the dictionary in the binarization of the text to transform the tokens into indices. Also note that we are using Encoder only architecture, so we only have source data.\n",
    "\n",
    "2- Binarize the labels (train.label, valid.label and test.label files) and put the output in <b>data/cls-books-bin/label</b>.\n",
    "\n",
    "Documentation: https://fairseq.readthedocs.io/en/latest/command_line_tools.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binarization\n",
    "\n",
    "`--only-source` : Only process the source language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/user/mambaforge/envs/llm/lib/python3.9/site-packages/torch/cuda/__init__.py:611: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    }
   ],
   "source": [
    "# binarize the tokenized reviews\n",
    "!(python ~/fairseq/fairseq_cli/preprocess.py \\\n",
    "              --only-source \\\n",
    "              --workers 8 \\\n",
    "              -s ../data/books/train.spm.review \\\n",
    "              --srcdict ../data/books/dict.txt \\\n",
    "              --destdir ../datacls-books-bin/input0\\\n",
    ")\n",
    "\n",
    "# !(python libs/fairseq/fairseq_cli/preprocess.py \\\n",
    "#               --only-source \\\n",
    "\n",
    "#               --workers 8)#fill me - binarize the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--no-progress-bar]\n",
      "                             [--log-interval LOG_INTERVAL]\n",
      "                             [--log-format {json,none,simple,tqdm}]\n",
      "                             [--log-file LOG_FILE] [--aim-repo AIM_REPO]\n",
      "                             [--aim-run-hash AIM_RUN_HASH]\n",
      "                             [--tensorboard-logdir TENSORBOARD_LOGDIR]\n",
      "                             [--wandb-project WANDB_PROJECT]\n",
      "                             [--azureml-logging] [--seed SEED] [--cpu] [--tpu]\n",
      "                             [--bf16] [--memory-efficient-bf16] [--fp16]\n",
      "                             [--memory-efficient-fp16]\n",
      "                             [--fp16-no-flatten-grads]\n",
      "                             [--fp16-init-scale FP16_INIT_SCALE]\n",
      "                             [--fp16-scale-window FP16_SCALE_WINDOW]\n",
      "                             [--fp16-scale-tolerance FP16_SCALE_TOLERANCE]\n",
      "                             [--on-cpu-convert-precision]\n",
      "                             [--min-loss-scale MIN_LOSS_SCALE]\n",
      "                             [--threshold-loss-scale THRESHOLD_LOSS_SCALE]\n",
      "                             [--amp] [--amp-batch-retries AMP_BATCH_RETRIES]\n",
      "                             [--amp-init-scale AMP_INIT_SCALE]\n",
      "                             [--amp-scale-window AMP_SCALE_WINDOW]\n",
      "                             [--user-dir USER_DIR]\n",
      "                             [--empty-cache-freq EMPTY_CACHE_FREQ]\n",
      "                             [--all-gather-list-size ALL_GATHER_LIST_SIZE]\n",
      "                             [--model-parallel-size MODEL_PARALLEL_SIZE]\n",
      "                             [--quantization-config-path QUANTIZATION_CONFIG_PATH]\n",
      "                             [--profile] [--reset-logging]\n",
      "                             [--suppress-crashes] [--use-plasma-view]\n",
      "                             [--plasma-path PLASMA_PATH]\n",
      "                             [--criterion {adaptive_loss,composite_loss,cross_entropy,ctc,fastspeech2,hubert,label_smoothed_cross_entropy,latency_augmented_label_smoothed_cross_entropy,label_smoothed_cross_entropy_with_alignment,label_smoothed_cross_entropy_with_ctc,label_smoothed_cross_entropy_with_rdrop,legacy_masked_lm_loss,masked_lm,model,nat_loss,sentence_prediction,sentence_prediction_adapters,sentence_ranking,tacotron2,speech_to_unit,speech_to_unit_2pass,speech_to_spectrogram,speech_to_spectrogram_2pass,speech_unit_lm_criterion,wav2vec,vocab_parallel_cross_entropy}]\n",
      "                             [--tokenizer {moses,nltk,space}]\n",
      "                             [--bpe {byte_bpe,bytes,characters,fastbpe,gpt2,bert,hf_byte_bpe,sentencepiece,subword_nmt}]\n",
      "                             [--optimizer {adadelta,adafactor,adagrad,adam,adamax,composite,cpu_adam,lamb,nag,sgd}]\n",
      "                             [--lr-scheduler {cosine,fixed,inverse_sqrt,manual,pass_through,polynomial_decay,reduce_lr_on_plateau,step,tri_stage,triangular}]\n",
      "                             [--scoring {bert_score,sacrebleu,bleu,chrf,meteor,wer}]\n",
      "                             [--task TASK] [-s SRC] [-t TARGET]\n",
      "                             [--trainpref FP] [--validpref FP] [--testpref FP]\n",
      "                             [--align-suffix FP] [--destdir DIR]\n",
      "                             [--thresholdtgt N] [--thresholdsrc N]\n",
      "                             [--tgtdict FP] [--srcdict FP] [--nwordstgt N]\n",
      "                             [--nwordssrc N] [--alignfile ALIGN]\n",
      "                             [--dataset-impl FORMAT] [--joined-dictionary]\n",
      "                             [--only-source] [--padding-factor N]\n",
      "                             [--workers N] [--dict-only]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --ip=127.0.0.1 --stdin=9003 --control=9001 --hb=9000 --Session.signature_scheme=\"hmac-sha256\" --Session.key=b\"9c03935e-ef72-4af4-93e5-280afa3ee7f6\" --shell=9002 --transport=\"tcp\" --iopub=9004 --f=/home/user/.local/share/jupyter/runtime/kernel-v2-5096Rh2B2TkB7osn.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/mambaforge/envs/llm/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3556: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# from fairseq_cli.preprocess import cli_main as preprocess_cli\n",
    "# preprocess_cli()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
