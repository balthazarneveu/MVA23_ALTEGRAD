{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlAfI8mCWAf3"
      },
      "source": [
        "<center><h2>ALTeGraD 2023<br>Lab Session 3: Transfer learning for NLP</h2> 24 / 10 / 2023<br> Dr. G. Shang, H. Abdine<br><br>\n",
        "\n",
        "\n",
        "<b>Student name:</b> Balthazar Neveu\n",
        "\n",
        "</center>\n",
        "\n",
        "<br><br>\n",
        "In this lab we will:\n",
        "* Implement and pretrain a language model with transformer architecture.\n",
        "* Use the pretrained model (transfer learning) to perform a sentiment analysis task which consists of classifying some books reviews into positive and negative ones.\n",
        "* Compare the performance of the pretrained model to a model trained from scratch.\n",
        " <br>\n",
        "\n",
        "<b>The deadline for this lab is October 31, 2023 11:59 PM.</b> More details about the submission and the architecture for this lab can be found in the handout PDF."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/pretraining_subset.txt\n",
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/dict.txt\n",
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/pretrained_model_4layers.pt\n",
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/train.review.spm\n",
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/train.label\n",
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/test.review.spm\n",
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/test.label\n",
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/sentencepiece.french.model\n",
        "!head -5 dict.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "IqukuIe0Rb_c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import math\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from pathlib import Path\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "path_vocab = Path(\"dict.txt\")\n",
        "assert path_vocab.exists()\n",
        "pretraining_path_data_train = Path(\"pretraining_subset.txt\")\n",
        "assert pretraining_path_data_train.exists()\n",
        "\n",
        "downstream_path_data_train = Path(\"train.review.spm\")\n",
        "assert downstream_path_data_train.exists()\n",
        "downstream_path_labels_train = Path(\"train.label\")\n",
        "assert downstream_path_labels_train.exists()\n",
        "downstream_path_data_valid = Path(\"test.review.spm\")\n",
        "assert downstream_path_data_valid.exists()\n",
        "downstream_path_labels_valid = Path(\"test.label\")\n",
        "assert downstream_path_labels_valid.exists()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "pretrained_model = Path(\"pretrained_model_4layers.pt\")\n",
        "assert pretrained_model.exists()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Tensor convention for NLP\n",
        "`[L, N, D]`\n",
        "- L sequence length\n",
        "- N batch size\n",
        "- V vocabulary dimension `ntokens`\n",
        "- E embeddings dimension `embedding_dim`\n",
        "- D hidden dimension\n",
        "\n",
        "### Simplification:\n",
        "- `E=D` hidden dimension set equal to th embedding dimension for simplicity in the following code `nhid = embedding_dim`\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FF6fjkqgN39"
      },
      "source": [
        "### The Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    \"\"\"Add fixed precomputed positional encoding to the embeddings\n",
        "    Add means (=literally addition)\n",
        "    \"\"\"\n",
        "    def __init__(self, embdeddings_dim: int , dropout: float =0.1, max_len: int =5000):\n",
        "        \"\"\"Precompute a positional encoding vector of length `max_len`\n",
        "\n",
        "        Args:\n",
        "            embdeddings_dim (int): dimension of word embeddings. Note th\n",
        "            dropout (float, optional): dropout ratio. Defaults to 0.1.\n",
        "            max_len (int, optional): maximum sequence length. Defaults to 5000.\n",
        "        \"\"\"\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        pe = torch.zeros(max_len, embdeddings_dim)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(\n",
        "            torch.arange(0, embdeddings_dim, 2).float() * (-math.log(10000.0) / embdeddings_dim)\n",
        "        )\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer(\"pe\", pe)\n",
        "\n",
        "    def forward(self, x: torch.FloatTensor) -> torch.FloatTensor:\n",
        "        \"\"\"Add positional encoding to the word embeddings.\n",
        "        Simply add the pre\n",
        "\n",
        "        Args:\n",
        "            x (torch.FloatTensor): embeddings tensor [L, N, D]\n",
        "\n",
        "        Returns:\n",
        "            torch.FloatTensor: Enhanced embeddings tensor, ready to go straight to the transformer blocks. \n",
        "        \"\"\"\n",
        "        x = x + self.pe[: x.size(0), :]\n",
        "        return self.dropout(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "p0cj9WkSFQwl"
      },
      "outputs": [],
      "source": [
        "class TransformerModel(nn.Module):\n",
        "    \"\"\"Transformer base model \n",
        "    =========================\n",
        "    - embedding from word to vectors\n",
        "    - add positional encoding\n",
        "    - `nlayers` * transformer blocks\n",
        "    \"\"\"\n",
        "    def __init__(self, ntokens:int, nhead:int, nhid:int, nlayers:int, dropout=0.5):\n",
        "        \"\"\"Transformer base model\n",
        "\n",
        "        Args:\n",
        "            ntokens (int): the size of vocabulary\n",
        "            nhead (int): number of heads in each of the MHA models\n",
        "            nhid (int): hidden dimension of the model. assume `embedding_dim` = `nhid`\n",
        "            nlayers (int): number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
        "            dropout (float, optional): dropout value. Defaults to 0.5.\n",
        "        \"\"\"\n",
        "        super(TransformerModel, self).__init__()\n",
        "        self.model_type = \"Transformer\"\n",
        "        embedding_dim = nhid # use the same embedding & hidden dimensions\n",
        "        self.encoder = nn.Embedding(ntokens, embedding_dim) # fill me, nhid = the dim_embed\n",
        "        self.pos_encoder = PositionalEncoding(nhid, dropout=dropout) #fill me, the PositionalEncoding class is implemented in the next cell\n",
        "        \n",
        "        encoder_layers = nn.TransformerEncoderLayer(\n",
        "            d_model=nhid, # input dimension to the transformer encoder layer\n",
        "            nhead=nhead, # number of heads for MHA (Multi-head attention)\n",
        "            dim_feedforward=nhid, # output dimension of the MLP on top of the transformer.\n",
        "            dropout=dropout\n",
        "        ) # we assume nhid = d_model = dim_feedforward\n",
        "        \n",
        "        self.transformer_encoder = nn.TransformerEncoder(\n",
        "            encoder_layers,\n",
        "            num_layers=nlayers\n",
        "        )\n",
        "        self.nhid = nhid\n",
        "        self.init_weights()\n",
        "    \n",
        "    @staticmethod\n",
        "    def generate_square_subsequent_mask(sz: int) -> torch.FloatTensor:\n",
        "        \"\"\"Generate causality mask = mask future tokens for next word prediction\n",
        "\n",
        "        Args:\n",
        "            sz (int): mask size M\n",
        "\n",
        "        Returns:\n",
        "            torch.FloatTensor: squares matrix [M, M] to mask the attention matrix.\n",
        "        \"\"\"\n",
        "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
        "        mask = (\n",
        "            mask.float()\n",
        "            .masked_fill(mask == 0, float(\"-inf\"))\n",
        "            .masked_fill(mask == 1, float(0.0))\n",
        "        )\n",
        "        return mask\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.1\n",
        "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def forward(\n",
        "            self, src: torch.LongTensor,\n",
        "            src_mask: torch.FloatTensor\n",
        "        ) -> torch.FloatTensor:\n",
        "        \"\"\"Embdeddings, positional encoders, go trough `nlayers` of residual {multi (`nhead`) attention heads + MLP}.\n",
        "\n",
        "        Args:\n",
        "            src (torch.LongTensor): [L, N, V] sequence of tokens , V=vocabu\n",
        "            src_mask (torch.FloatTensor): [L, L] squared mask\n",
        "\n",
        "        Returns:\n",
        "            torch.FloatTensor: encoded sequence [L, N, D]\n",
        "        \"\"\"\n",
        "        src = self.encoder(src) * math.sqrt(self.nhid) #embed [L, N, V] -> [L, N, E]\n",
        "        src = self.pos_encoder(src) # [L, N, E]  - add positional encoding\n",
        "        output = self.transformer_encoder(src, mask=src_mask)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "kt2QQohaFZry"
      },
      "outputs": [],
      "source": [
        "class ClassificationHead(nn.Module):\n",
        "    def __init__(self, nhid: int, nclasses: int):\n",
        "        \"\"\"Linear classification head -> returns logits (not probabilities)\n",
        "\n",
        "        Args:\n",
        "            nhid (int): hidden dimension\n",
        "            nclasses (int): number of classes.\n",
        "        \"\"\"\n",
        "        super(ClassificationHead, self).__init__()\n",
        "        self.decoder = nn.Linear(nhid, nclasses)\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.1\n",
        "        self.decoder.bias.data.zero_()\n",
        "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def forward(self, src: torch.FloatTensor) -> torch.FloatTensor:\n",
        "        \"\"\"Classify encoded feature vectors\n",
        "\n",
        "        Args:\n",
        "            src (torch.FloatTensor): Encoded feature vectors [L, N, D]\n",
        "\n",
        "        Returns:\n",
        "            torch.FloatTensor: Logits (no softmax applied)\n",
        "        \"\"\"\n",
        "        output = self.decoder(src)\n",
        "        return output\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, ntoken: int, nhead: int, nhid: int, nlayers: int, nclasses: int, dropout: float=0.5):\n",
        "        \"\"\"TransformerModel+ClassificationHead\n",
        "        \n",
        "        This allows defining a model for next word prediction (classification with ntoken classes)\n",
        "        Or other downstream tasks if the base `TransformerModel` is pretrained\n",
        "\n",
        "        Args:\n",
        "        \n",
        "            ntoken (int): size of vocabulary for (`TransformerModel`)\n",
        "            nhead (int): number of heads in each of the MHA models (`TransformerModel`)\n",
        "            nhid (int): hidden dimension of the model. assume `embedding_dim` = `nhid`\n",
        "            nlayers (int):  number of nn.TransformerEncoderLayer in nn.TransformerEncoder (`TransformerModel`)\n",
        "            nclasses (int): number of output classes in the classifier `ClassificationHead`\n",
        "                - =size of vocabulary for next word prediction\n",
        "                - other for downstream tasks like sentiment analyzis.\n",
        "            dropout (float, optional): _description_. Defaults to 0.5.  (`TransformerModel`)\n",
        "        \"\"\"\n",
        "        super(Model, self).__init__()\n",
        "        self.base = TransformerModel(ntoken, nhead, nhid, nlayers, dropout=dropout)\n",
        "        self.classifier = ClassificationHead(nhid, nclasses)\n",
        "\n",
        "    def forward(self, src:torch.LongTensor, src_mask: torch.FloatTensor) -> torch.FloatTensor:\n",
        "        \"\"\"Encoder + linear classifier\n",
        "\n",
        "        Args:\n",
        "            src (torch.LongTensor): sequence of tokens [L, N, V]\n",
        "            src_mask (torch.FloatTensor): [L, L] squared mask.\n",
        "\n",
        "        Returns:\n",
        "            torch.FloatTensor: [N, C]\n",
        "        \"\"\"\n",
        "        # base model\n",
        "        x = self.base(src, src_mask)\n",
        "        # classifier model\n",
        "        output = self.classifier(x)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Causal attention mask & useless computations (question 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10 useless computations for a sequence of 5 tokens\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[0., -inf, -inf, -inf, -inf],\n",
              "        [0., 0., -inf, -inf, -inf],\n",
              "        [0., 0., 0., -inf, -inf],\n",
              "        [0., 0., 0., 0., -inf],\n",
              "        [0., 0., 0., 0., 0.]])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sentence_length_test = 5\n",
        "src_mask = TransformerModel.generate_square_subsequent_mask(sentence_length_test)\n",
        "useless_computations = sentence_length_test*(sentence_length_test-1)//2\n",
        "assert int( ((-src_mask).isinf()).sum()) == useless_computations\n",
        "print(f\"{useless_computations} useless computations for a sequence of {sentence_length_test} tokens\")\n",
        "src_mask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Unit test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "rhb2gkUhJMR0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/bneveu/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:255: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because  encoder_layer.self_attn.batch_first was not True\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 6, 100])\n"
          ]
        }
      ],
      "source": [
        "def test_transformer_based_classifier():\n",
        "    ntokens = 100 #  V the size of vocabulary\n",
        "    nhid = 200  # hidden dimension\n",
        "    nlayers = 4  # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
        "    nhead = 2  # the number of heads in the multiheadattention models\n",
        "    dropout = 0  # the dropout value\n",
        "    nclasses = ntokens # classification to get output words in the same language\n",
        "    model = Model(ntokens, nhead, nhid, nlayers, nclasses, dropout).to(device)\n",
        "    dummy_input = torch.tensor([[2, 6, 2, 5, 43, 21], [8, 5, 3, 42, 43, 21]]).to(device)\n",
        "\n",
        "    sequence_length = dummy_input.shape[0] #L\n",
        "    batch_size = dummy_input.shape[1] #N\n",
        "\n",
        "    src_mask = TransformerModel.generate_square_subsequent_mask(sequence_length).to(device)\n",
        "    assert list(src_mask.shape) == [sequence_length,sequence_length]\n",
        "    # batch dimension N is not involved in the mask computation! We assume all sequences in the batch has the same sequence length L\n",
        "    out = model.forward(dummy_input, src_mask)\n",
        "    expected_size = [sequence_length, batch_size, nclasses]\n",
        "    assert list(out.shape) == expected_size, f\"{out.shape}, {expected_size}\"\n",
        "    print(out.shape)\n",
        "test_transformer_based_classifier()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i74NN897Fcit"
      },
      "source": [
        "## Vocabulary and Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "vFdH_-JeFbGA"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "▁trop <sos>\n"
          ]
        }
      ],
      "source": [
        "SRC = \"source_sequence\"\n",
        "TGT = \"target\"\n",
        "SOS = \"<sos>\"\n",
        "PAD = \"<pad>\"\n",
        "EOS = \"<eos>\"\n",
        "OOV = \"<oov>\"\n",
        "LM_TASK = \"language_modeling\"\n",
        "DS_TASK = \"classification\"\n",
        "token2ind = {SOS: 0, PAD : 1, EOS: 2, OOV: 3} # the 4 first indices are reserved to special tokens\n",
        "offset = max(token2ind.values())+1\n",
        "with open(path_vocab, \"r\") as f:\n",
        "    for idx, line in enumerate(f):\n",
        "        word = line.split()[0].strip()\n",
        "        token2ind[word] = idx+offset\n",
        "ind2token = {index: token for token, index in token2ind.items()}\n",
        "print(ind2token[1111], ind2token[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOExGODajN8p"
      },
      "source": [
        "### Data Loader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Y0jN-Ar9i5Q1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Tuple\n",
        "\n",
        "class Dataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        path_documents: Path,\n",
        "        path_labels: Path = None,\n",
        "        token2ind: Dict[str, int]={},\n",
        "        max_len: int=512,\n",
        "        task: str=LM_TASK,\n",
        "    ):\n",
        "        self.task = task\n",
        "        self.max_len = max_len\n",
        "        self.token2ind = token2ind\n",
        "        self.documents = []\n",
        "        self.labels = []\n",
        "        with open(path_documents, \"r\") as f1:\n",
        "            for line in f1:\n",
        "                self.documents.append(line.strip())\n",
        "        if task == \"classification\":\n",
        "            with open(path_labels, \"r\") as f1:\n",
        "                for line in f1:\n",
        "                    self.labels.append(int(line.strip()))\n",
        "            assert len(self.labels) == len(self.documents)\n",
        "        self.oov_index = self.token2ind[OOV]\n",
        "    def __len__(self):\n",
        "        return len(self.documents)\n",
        "\n",
        "    def __getitem__(self, index: int):\n",
        "        sequence = self.documents[index].split()\n",
        "        if len(sequence) > self.max_len - 1:\n",
        "            sequence = sequence[: self.max_len - 1] \n",
        "        \n",
        "        source_sequence = [self.token2ind.get(token, self.oov_index) for token in sequence]\n",
        "        source_sequence.insert(0, self.token2ind[SOS]) \n",
        "        # (constract the input sequence using token2ind, sequence and special tokens)\n",
        "        if self.task == LM_TASK:\n",
        "            target = source_sequence[1:] # offset the sequence by one\n",
        "            # A, B , C, D , <EOS>\n",
        "            target.append(self.token2ind[EOS])\n",
        "            assert len(target) == len(source_sequence)\n",
        "        elif self.task == DS_TASK:\n",
        "            target = [self.labels[index]]\n",
        "        sample = {\n",
        "            SRC: torch.tensor(source_sequence),\n",
        "            TGT: torch.tensor(target),\n",
        "        }\n",
        "        return sample\n",
        "\n",
        "\n",
        "def collate_sentences_keep_dim(batch: List[Dict[str, torch.LongTensor]]) -> Tuple[torch.LongTensor, torch.LongTensor]:\n",
        "    \"\"\"Uniformize batches (have the same sentence length with padding for all sentences across the batch)\n",
        "\n",
        "    Args:\n",
        "        batch (List[Dict[str, torch.LongTensor]]): List of dict samples containing \n",
        "\n",
        "    Returns:\n",
        "        Tuple[torch.LongTensor, torch.LongTensor]: \n",
        "            - source [L, N, V]\n",
        "            where L is the maximum length along all sentences in the batch\n",
        "            - target \n",
        "                - [L, N, V] for language modeling task\n",
        "                - [N, C] for classification with C the number of classes\n",
        "            \n",
        "    \"\"\"\n",
        "    source_sequences = pad_sequence(\n",
        "        #we use padding to match the length of the sequences in the same batch\n",
        "        [sample[SRC] for sample in batch], padding_value=token2ind[PAD]\n",
        "    )\n",
        "    target = pad_sequence(\n",
        "        [sample[TGT] for sample in batch], padding_value=token2ind[PAD]\n",
        "    )\n",
        "    return source_sequences, target\n",
        "\n",
        "\n",
        "def collate_sentences(batch: List[Dict[str, torch.LongTensor]]) -> Tuple[torch.LongTensor, torch.LongTensor]:\n",
        "    source_sequences, target = collate_sentences_keep_dim(batch)\n",
        "    return source_sequences, target.reshape(-1)\n",
        "\n",
        "def get_loader(\n",
        "    path_documents :Path,\n",
        "    path_labels: Path = None,\n",
        "    token2ind : Dict[str, int]={},\n",
        "    max_len: int =512,\n",
        "    batch_size: int = 32,\n",
        "    task: str=LM_TASK,\n",
        "    collate_fn = collate_sentences,\n",
        "    shuffle=True\n",
        "):\n",
        "    dataset = Dataset(\n",
        "        path_documents,\n",
        "        path_labels=path_labels,\n",
        "        token2ind=token2ind,\n",
        "        max_len=max_len,\n",
        "        task=task,\n",
        "    )\n",
        "    data_loader = DataLoader(\n",
        "        dataset=dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=shuffle,\n",
        "        collate_fn=collate_fn,\n",
        "        pin_memory=True,\n",
        "        drop_last=True,\n",
        "    )\n",
        "    return data_loader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sanity check on data loader and collate functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<sos> Les chauds et les froids d ' un déplacement présidentiel ( M itter rand ) ou encore la prise en otage d ' un air bus ministériel ( cinq ministres , vingt députés et .\n",
            "Les chauds et les froids d ' un déplacement présidentiel ( M itter rand ) ou encore la prise en otage d ' un air bus ministériel ( cinq ministres , vingt députés et . <eos>\n",
            "<sos> Les hommes sont encore en train de mesurer leur pouce .\n",
            "Les hommes sont encore en train de mesurer leur pouce . <eos>\n",
            "<sos> La recherche est possible directement sur la carte , ou bien en rentrant une adresse de son choix .\n",
            "La recherche est possible directement sur la carte , ou bien en rentrant une adresse de son choix . <eos>\n",
            "<sos> Tous les jours nous cherchons pour vous sur le web les articles , vidéos et documentaires qui nous paraissent les plus pertinents et utiles à tous .\n",
            "Tous les jours nous cherchons pour vous sur le web les articles , vidéos et documentaires qui nous paraissent les plus pertinents et utiles à tous . <eos>\n",
            "<sos> D ' abord , le Hezbollah a toujours eu les mains sales et donne la naus ée lorsqu ' on voit le nombre d ' activités illégales qui participent de son financement : tous les trafics , armes , cigarettes , contrefaçon , drogues , passent par ses mains , qui ne sont plus innoc entes depuis longtemps .\n",
            "D ' abord , le Hezbollah a toujours eu les mains sales et donne la naus ée lorsqu ' on voit le nombre d ' activités illégales qui participent de son financement : tous les trafics , armes , cigarettes , contrefaçon , drogues , passent par ses mains , qui ne sont plus innoc entes depuis longtemps . <eos>\n"
          ]
        }
      ],
      "source": [
        "N = 32\n",
        "data_loader = get_loader(\n",
        "    pretraining_path_data_train,\n",
        "    token2ind=token2ind,\n",
        "    batch_size=N,\n",
        "    task=LM_TASK,\n",
        "    collate_fn=collate_sentences_keep_dim\n",
        ")\n",
        "token2ind[OOV]\n",
        "it = iter(data_loader)\n",
        "\n",
        "def tensor_to_sentence(tensor_sentence):\n",
        "        return \" \".join([ind2token.get(el, \"not found\").replace(\"▁\", \"\") for el in tensor_sentence.numpy() if el != token2ind[PAD]])\n",
        "\n",
        "for u in range(5):\n",
        "    sampled_batch = next(it)\n",
        "    # first[0].shape, first[1].shape\n",
        "    # first[0][:, 0] # first sentence # L, N\n",
        "    first_sentence = sampled_batch[0][:, 0]\n",
        "    def tensor_to_sentence(tensor_sentence):\n",
        "        return \" \".join([ind2token.get(el, \"not found\").replace(\"▁\", \"\") for el in tensor_sentence.numpy() if el != token2ind[PAD]])\n",
        "    print(tensor_to_sentence(first_sentence))\n",
        "    print(tensor_to_sentence(sampled_batch[1][:, 0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "50001\n"
          ]
        }
      ],
      "source": [
        "ntokens = len(ind2token) # the size of vocabulary\n",
        "print(len(ind2token))\n",
        "nhid = 200  # the dimension of the feedforward network model in nn.TransformerEncoder\n",
        "nlayers = 4  # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
        "nhead = 2  # the number of heads in the multiheadattention models\n",
        "dropout = 0  # the dropout value\n",
        "\n",
        "nclasses = 2 # for classification task only\n",
        "\n",
        "model_pretraining = Model(ntokens, nhead, nhid, nlayers, ntokens, dropout).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# optimization parameters\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=token2ind['<pad>'])\n",
        "lr = 0.0003  # learning rate\n",
        "optimizer = torch.optim.Adam(model_pretraining.parameters(), lr=lr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTns4lHrjUTa"
      },
      "source": [
        "## Training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "4_jwosiLjRsS"
      },
      "outputs": [],
      "source": [
        "def train(\n",
        "    model,\n",
        "    path_data_train: Path,\n",
        "    path_labels_train: Path =None,\n",
        "    path_data_valid: Path = None,\n",
        "    save_interval: int =-1,\n",
        "    log_interval: int=5,\n",
        "    task: str=LM_TASK,\n",
        "    batch_size: int =32,\n",
        "    max_len=512,\n",
        "    epoch=0,\n",
        "    name=\"\"\n",
        "):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    ntokens = len(token2ind)\n",
        "    data_loader = get_loader(\n",
        "        path_data_train,\n",
        "        path_labels_train,\n",
        "        token2ind,\n",
        "        max_len=max_len,\n",
        "        task=task,\n",
        "        batch_size=batch_size,\n",
        "    )\n",
        "\n",
        "    losses = []\n",
        "    for idx, data in enumerate(data_loader): # get a batch of samples\n",
        "        # reset gradients to zero\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        src_mask = TransformerModel.generate_square_subsequent_mask(data[0].size(0)).to(\n",
        "            device\n",
        "        )\n",
        "        input = data[0].to(device)\n",
        "        # forward pass\n",
        "        output = model(input, src_mask) \n",
        "        if task == DS_TASK:\n",
        "            output = output[-1:, :]  # last vector only\n",
        "        output = output.view(-1, output.shape[-1])\n",
        "        target = data[1]\n",
        "        target = target.to(device)\n",
        "        loss =  criterion(output, target) # CROSS ENTROPY\n",
        "        loss.backward() # compute gradients\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5) # prevent exploding gradient\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        if idx % log_interval == 0 and idx > 0:\n",
        "            cur_loss = total_loss / log_interval\n",
        "            print(\n",
        "                f\"| epoch {epoch:3d} | {idx:5d}/{len(data_loader):5d} steps | \"+\n",
        "                f\"loss {cur_loss:5.5f} | ppl {math.exp(cur_loss):8.3f}\"\n",
        "            )\n",
        "            losses.append(cur_loss)\n",
        "            total_loss = 0\n",
        "    if epoch % save_interval == 0 and save_interval>=1:\n",
        "        torch.save(model, f\"weights_{task}{name}_{epoch:02d}.pt\")\n",
        "    return losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "# EMPTY THE GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0m11g4ScjZaR"
      },
      "outputs": [],
      "source": [
        "#pretraining on a tiny subset\n",
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "log_interval = 500\n",
        "epochs = 2\n",
        "for epoch in range(1, epochs + 1): #5\n",
        "    train(\n",
        "        pretraining_path_data_train,\n",
        "        save_interval=-1,\n",
        "        task=LM_TASK,\n",
        "        batch_size=16,\n",
        "        max_len=64,\n",
        "        log_interval=log_interval,\n",
        "        epoch=epoch\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MeOM1dOvkO4e"
      },
      "source": [
        "## Text Generation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "-BcBC6FSkMH3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/bneveu/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:255: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because  encoder_layer.self_attn.batch_first was not True\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_pretraining = Model(ntokens, nhead, nhid, nlayers, ntokens).to(device)\n",
        "\n",
        "#load the checkpoint\n",
        "checkpoint = torch.load('pretrained_model_4layers.pt')\n",
        "#load state dict\n",
        "model_pretraining.load_state_dict(checkpoint['model_state_dict'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "tBRRVsWqlIoQ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['▁Bonjour', '▁les', '▁amis', '!']\n",
            "Bonjour les amis!\n"
          ]
        }
      ],
      "source": [
        "import sentencepiece as spm\n",
        "\n",
        "s = spm.SentencePieceProcessor(model_file='sentencepiece.french.model') #load sentencepiece model\n",
        "\n",
        "#examples\n",
        "encoded = s.encode_as_pieces(\"Bonjour les amis!\")\n",
        "decoded = s.decode_pieces(encoded)\n",
        "print(encoded)\n",
        "print(decoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "TtLlV05pkQI3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bonjour les gens qui ont été très accueillants et sympathiques.\n"
          ]
        }
      ],
      "source": [
        "def infer_next_token(sent, model):\n",
        "    model.eval()\n",
        "    sent_pieces = s.encode_as_pieces(sent)\n",
        "    source = [token2ind['<sos>']] + [token2ind[el] for el in sent_pieces] # list of tokens\n",
        "    source = torch.tensor(source).to(device)\n",
        "    source = source.reshape(-1, 1)\n",
        "    src_mask = model.base.generate_square_subsequent_mask(source.size(0)).to(device)\n",
        "    out = model(source, src_mask)\n",
        "    next_token_ind =  int(torch.argmax(torch.nn.Softmax(dim=-1)(out[-1, 0, :])).detach()) #FORCE N=1\n",
        "    return next_token_ind, out\n",
        "\n",
        "def infer_next_tokens(sent, model, max_len=50):\n",
        "    next_token_list = []\n",
        "    next_token_index=-1\n",
        "    iter = 0\n",
        "    while next_token_index!=token2ind[EOS]:\n",
        "        if iter>max_len:\n",
        "            break\n",
        "        next_token_index, out = infer_next_token(sent, model)\n",
        "        next_token = ind2token.get(next_token_index)\n",
        "        sent+= next_token\n",
        "        next_token_list.append(next_token)\n",
        "    return next_token_list\n",
        "\n",
        "\n",
        "sent = \"Bonjour les\"\n",
        "out = infer_next_tokens(sent, model_pretraining)\n",
        "print(sent + \" \" + s.decode_pieces(out[:-1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lp7mjVzomoZ3"
      },
      "source": [
        "### Supervised task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2000 sentences in the validation set\n"
          ]
        }
      ],
      "source": [
        "data_loader_validation = get_loader(\n",
        "    downstream_path_data_valid,\n",
        "    downstream_path_labels_valid,\n",
        "    token2ind=token2ind,\n",
        "    # batch_size=20,\n",
        "    batch_size=1, # Let's use a batch size of 1 so a sentence always has maximum length\n",
        "    task='classification',\n",
        "    shuffle=False # AVOID SHUFFLING FOR OBVIOUS REASONS - even if we're going through the whole validation set - let's do it in the same order everytime (batches will always be the same, no matter the configuration)\n",
        ")\n",
        "print(f\"{len(data_loader_validation.dataset)} sentences in the validation set\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<sos> J ' ai lu ce livre car dans ma ville , tout le monde s ' en sert et le commande . C ' est ma pharmaci enne qui me l ' a conseillé , elle a t ellement maig ri que je lui ai demandé ce qu ' elle avait fait et au lieu de me vendre du per li mp in pin en gé lules , elle m ' a conseillé ce livre à 5 euros . Bien sur , il faut faire un effort pour perdre 25 kilos mais avec le livre , j ' avais un compagnon de route . L ' auteur a su me parler simplement avec des arguments très forts et surtout j ' ai senti qu ' il connaissait bien des cas comme le mien . Il y a dans son texte de l ' expérience , de la simplicité et de la compassion pour ceux qui comme moi vivait avec tout ce poids qui me col lait au corps sans jamais vouloir partir . Je ne crois pas qu ' il existe un régime miracle qui surp asse les autres mais je crois vraiment qu ' il y a des personnes qui savent parler aux autres et faire n aitre des déclic s . Je croyais être faible mais ce livre m ' a rendu forte , je l ' ai t ellement ann oté que j ' en suis à mon troisième . Quand on est très grosse comme je l ' ai été , les non - gros ne vous comprennent pas ou ont peur de vous frois ser en vous en parlant , alors ce livre a été comme un compagnon - journal . Je suis pé dic ure et je l ' ai conseillé à tous mes clients gros dont je lis la souffrance sur les pieds déform és et gonf lés . je rends aux autres le service que m ' a rendu ma pharmaci enne . Je le conseille à tous ceux qui souffrent car après avoir maig ri c ' est un tel bonheur que j ' ai accepté de passer à la phase 3 de ce plan qui impose 10 jours de consolidation pour chaque kilo perdu en s ' ouvrant progressivement à tout . Maintenant , je suis en phase 4, c ' est à dire que je mange de tout sauf le jeudi où je contrôle . Je remercier ai jamais assez l ' auteur de ce livre .\n",
            "True\n",
            "<sos> Recettes appréciées de toute la famille ( petits et grands ) de plus on peut faire son régime en ayant des invités , ils n ' y voient que du feu . Pour la vinaigrette il ne faut surtout pas dire quelle est faite avec de l ' huile de par af ine alors elle est excellente , s inon .... Le régime est super efficace il ne fatigue pas du tout . J ' encourage ceux qui ont des kilos en trop , à le faire , il ne faut pas beaucoup de volonté car on mange toujours à sa faim .\n",
            "True\n",
            "<sos> Be ig be der se dra pe de mystère . Il pose avec des airs sombres , en rou lé dans une cape noire , façon Z oz o ( com mentaire écrit sur fond musical : \" Z orro est arrivé \" de Henri Salvador ). Et pourtant , le seul mystère réservé aux ni ais , serait celui du \" mi ra cule ux \" succès obtenu sans aucun talent . La publicité a montré que le talent n ' était pas une condition nécessaire pour réussir . Un plat de nouilles a du succès s ' il est bien médi atisé . Les motoc ro ttes firent beaucoup pour la popularité du maire de Paris , Jacques C . \" Un roman français \" est un plat sans saveur , composé d ' ingrédients sans relief , qui n ' é veille ni l ' appétit , ni l ' esprit . Vous en doute z ? Au chapitre de l ' éducation sexuelle , cette autobiographie , nous conte les premiers ém ois à 13 ans de l ' auteur qui embrasse sur la bouche avec la langue dehors . Les goûts littéraires sont présentés à la manière d ' un feu d ' artifice Internet . Vous n ' avez rien lu de ce dont vous parlez . Pas grave , c itez p êle - mêle des noms d ' écriv ains aux cons on ances exotiques , anglo - sax onnes . Une pause . Qu ' il est fort ce Z oz o ! Be ig be der , dans la lignée de l ' émission \" lit té raire \" qu ' il avait \" anim ée \" nous apprend que San Antonio ( sic !) est un auteur de droite , comme Rab elais ( !). Rab elais , un écrivain de droite ! Le délire , l ' in culture et l ' absence de syntaxe soutiennent pénible ment la démonstration : Be ig be der appréci ait ces écrivains de droite car ils sont rigol os ( je cite ) alors que les auteurs de gauche , Sartre , Camus ne le sont pas ... à l ' exception précise - t - il des \" M ots \" et de \" La Ch ute \". Ces ouvrages seraient donc \" rig olos \". En quoi Céline , \" écrivain de droite \" peut - il être rigolo ? Trou bles ( ment aux ). Ce dro gué , coc aï nom ane , cra che sur la justice , les mesures de salubrité publique prises pour le sauver de lui - même . Z oz o était p af . Z oz o était malade . Z oz o était en infraction . Ah , ces 17 heures de mise \" en prison \" ( au poste de police seulement ) valent les années de goul ag de Sol j én its yne , celles du camp d ' extermination de Prim o Levi , celles de D\n",
            "False\n",
            "<sos> Un petit livre si facile à lire et si puissant . Le racisme ne peut pas résister longtemps devant une telle mise en perspective . Les \" ra ces \" soi - disant dominantes d ' aujourd ' hui ne seront pas celles de demain ... Un excellent livre à lire et offrir aussi souvent que l ' on peut\n",
            "True\n",
            "<sos> Saint - Ex upéry réalise à travers l ' histoire du petit prince l ' un des plus grands chefs - d ' oeuvres littéraires , poétiques et révolu tionnaires de tous les temps . La morale magique \" l ' essentiel est invisible pour les yeux \" semble rés onner partout où notre regard se porte , vibrant dans l ' harmonie retrouvée des premiers matins du monde . Change ton regard , là est la clé ! semble nous indiquer Saint - Ex . Ange d ' espoir , reviens ! nous lance - t - il en re tenant des larmes d ' enfant . Ce conte philosophique est une ode à la vie , au bonheur , à la compréhension et à la fraternité humaine . Il s ' agit d ' un testament poétique , d ' une oeuvre intemp orelle et universelle , d ' une tentative pour restaurer le lien secret entre l ' Homme et l ' Univers , entre l ' Homme et Lui - même . Mais la portée véritable et finale est d ' un autre ordre : la Fleur est destinée ...\n",
            "True\n",
            "<sos> je suis tres de çue de la taille de ce livre ( il tiens dans le creux de la main ... et les recettes y sont N ULES ( il n ' y a rien de nouveau et d ' in ven tif ) je ne le recommande a personne !!!\n",
            "False\n",
            "<sos> Ce livre n ' est pas cher et il comporte un grand nombre de recettes originales . Par contre , il est bourré de fautes : soit vous avez des ingrédients qui sont oubliés dans la recette ( quand les mettre ? ), ou la recette demandent des ingrédients mais ils ne sont pas dans la liste des ingrédients ( quelle quantité mettre ?) A acheter en connaissance de cause ...\n",
            "False\n",
            "<sos> Un roman de rentrée de la fille de B HL , a - t - on vraiment besoin d ' en dire plus pour vous convaincre que la lecture de cet ouvrage , au style aussi peu inspiré que lourd , vous fera perdre de précieuses heures ? A mon humble avis , le seul fait d ' être la fille d ' un philosophe milliardaire ne donne pas automatiquement toutes les qualités requises pour faire un bon écrivain . Pour ma part j ' ai assez rapidement laissé tomber ce bouquin pour me plonger dans .\n",
            "False\n",
            "<sos> Contrairement au commentaire de Seb , je trouve ce livre vraiment très pratique . Il y a certes quelques erreurs comme l ' IG du cass oulet effectivement non nul . Mais le reste de la ligne montre qu ' il y a bien de n bre uses glucides et plus important qu ' il est à limiter pour les diabétiques . Les pages sont bien dans le bon ordre ( c ' est ton exemplaire qui est mauvais Seb !) et surtout il n ' y a pas d ' erreurs sur les quantités de G , L ou P car le n bre noté est pour la quantité indiquée . Donc pour le N ute lla pas d ' erreur à noter puisqu ' il s ' agit de 15 g rs de produit étudié et pas la valeur pour 100 g rs comme sur le pot . Donc monsieur Seb devrait chercher à mieux comprendre le tableau avant de critiquer ce fabuleux outils qui a tout de même le mérite , en format poche , de regrouper 11 40 aliments ! Trés utile pour les diab étique .\n",
            "True\n",
            "<sos> j ' ai acheté ce bouquin sur le seul nom de Gran gé . On ne m ' y reprendra plus ! On n ' y croit pas un seul instant , c ' est creux , comme l ' héroïne . Je me suis forcée à le finir , en croyant au miracle . Que n enni !\n",
            "False\n",
            "<sos> Je dis non à la facilité ..... et non à l ' auteur qui n ' a même pas fait l ' effort de rencontrer la famille avant d ' écrire son bouquin , qui ne connait rien au personnage de Gregory et encore moins à l ' artiste !! ..... Comment parler correctement de quelqu ' un qu ' on a jamais rencontré de son vivant , et dont on ne s ' est intéressé qu ' après sa mort ??? Franchement à la place de l ' auteur j ' aurais vraiment honte de vouloir profiter de la douleur des fans !! Si vous voulez lire un bon livre sur GRE G OR Y LE MAR CH AL , achetez plutôt celui de sa soeur Leslie \" Mon Frère , l ' Ar tiste \" et en plus vous fer rez une bonne action , puisque tout est entièrement re versé à l ' association GRE G OR Y LE MAR CH AL !!\n",
            "False\n"
          ]
        }
      ],
      "source": [
        "for idx, sentence_batch in enumerate(data_loader_validation):\n",
        "    if idx>10:\n",
        "        break\n",
        "    first_sentence = sentence_batch[0][:, 0]\n",
        "    print(tensor_to_sentence(first_sentence))\n",
        "    print(bool(sentence_batch[1][0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "_MLfvjiom2SL"
      },
      "outputs": [],
      "source": [
        "# a function to evaluate the validation accuracy of the model.\n",
        "def evaluate_accuracy(data_loader: DataLoader, model):\n",
        "    accuracy = 0\n",
        "    for _idx, sentence_batch in enumerate(data_loader):\n",
        "        input_sentences = sentence_batch[0].to(device)\n",
        "        target_labels = sentence_batch[1].to(device)\n",
        "        logits = model(input_sentences, src_mask=None)[-1, ...]\n",
        "        predicted_class = torch.argmax(logits)\n",
        "        accuracy += torch.sum(predicted_class==target_labels).detach()\n",
        "        # print(accuracy)\n",
        "        # print(logits.shape, sentence_batch[1].shape)\n",
        "        # torch.argmax(logits)\n",
        "    accuracy = float(accuracy)/len(data_loader.dataset)\n",
        "    return accuracy\n",
        "\n",
        "def test_evaluate_accuracy():\n",
        "    model_ds = Model(ntokens, nhead, nhid, nlayers, 2, dropout).to(device)\n",
        "    model_ds.eval()\n",
        "    acc = evaluate_accuracy(\n",
        "        data_loader_validation,\n",
        "        model_ds\n",
        "    )\n",
        "    print(f\"accuracy of a randomly initalized classifier {acc} ~ shall be around 0.5\")\n",
        "\n",
        "# test_evaluate_accuracy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "qzmx7T7xoa6v"
      },
      "outputs": [],
      "source": [
        "#save the base model to be loaded later in the fine-tuning phase\n",
        "torch.save({\"model_state_dict\": model_pretraining.base.state_dict(),}, \"pretrained_model_4layers_no_class_head.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "i-xclMCpnVpw"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/bneveu/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:255: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because  encoder_layer.self_attn.batch_first was not True\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=====Trainig FROM SCRATCH======\n",
            "| epoch   1 |    50/ 1600 steps | loss 0.80170 | ppl    2.229\n",
            "| epoch   1 |   100/ 1600 steps | loss 1.89372 | ppl    6.644\n",
            "| epoch   1 |   150/ 1600 steps | loss 1.51040 | ppl    4.529\n",
            "| epoch   1 |   200/ 1600 steps | loss 1.09961 | ppl    3.003\n",
            "| epoch   1 |   250/ 1600 steps | loss 1.62145 | ppl    5.060\n",
            "| epoch   1 |   300/ 1600 steps | loss 1.94498 | ppl    6.994\n",
            "| epoch   1 |   350/ 1600 steps | loss 1.23516 | ppl    3.439\n",
            "| epoch   1 |   400/ 1600 steps | loss 1.00855 | ppl    2.742\n",
            "| epoch   1 |   450/ 1600 steps | loss 1.88957 | ppl    6.617\n",
            "| epoch   1 |   500/ 1600 steps | loss 1.60197 | ppl    4.963\n",
            "| epoch   1 |   550/ 1600 steps | loss 1.90519 | ppl    6.721\n",
            "| epoch   1 |   600/ 1600 steps | loss 0.80170 | ppl    2.229\n",
            "| epoch   1 |   650/ 1600 steps | loss 1.52158 | ppl    4.579\n",
            "| epoch   1 |   700/ 1600 steps | loss 1.11996 | ppl    3.065\n",
            "| epoch   1 |   750/ 1600 steps | loss 1.41844 | ppl    4.131\n",
            "| epoch   1 |   800/ 1600 steps | loss 1.40640 | ppl    4.081\n",
            "| epoch   1 |   850/ 1600 steps | loss 1.52994 | ppl    4.618\n",
            "| epoch   1 |   900/ 1600 steps | loss 1.51956 | ppl    4.570\n",
            "| epoch   1 |   950/ 1600 steps | loss 1.10344 | ppl    3.015\n",
            "| epoch   1 |  1000/ 1600 steps | loss 1.79648 | ppl    6.028\n",
            "| epoch   1 |  1050/ 1600 steps | loss 0.94176 | ppl    2.564\n",
            "| epoch   1 |  1100/ 1600 steps | loss 1.32788 | ppl    3.773\n",
            "| epoch   1 |  1150/ 1600 steps | loss 1.12048 | ppl    3.066\n",
            "| epoch   1 |  1200/ 1600 steps | loss 1.60444 | ppl    4.975\n",
            "| epoch   1 |  1250/ 1600 steps | loss 1.06432 | ppl    2.899\n",
            "| epoch   1 |  1300/ 1600 steps | loss 1.05312 | ppl    2.867\n",
            "| epoch   1 |  1350/ 1600 steps | loss 1.35903 | ppl    3.892\n",
            "| epoch   1 |  1400/ 1600 steps | loss 1.81934 | ppl    6.168\n",
            "| epoch   1 |  1450/ 1600 steps | loss 1.21204 | ppl    3.360\n",
            "| epoch   1 |  1500/ 1600 steps | loss 1.35993 | ppl    3.896\n",
            "| epoch   1 |  1550/ 1600 steps | loss 1.69906 | ppl    5.469\n",
            "from_scratch=True - VALIDATION ACCURACY 0.6365\n",
            "| epoch   2 |    50/ 1600 steps | loss 1.15035 | ppl    3.159\n",
            "| epoch   2 |   100/ 1600 steps | loss 1.82475 | ppl    6.201\n",
            "| epoch   2 |   150/ 1600 steps | loss 1.64020 | ppl    5.156\n",
            "| epoch   2 |   200/ 1600 steps | loss 1.13063 | ppl    3.098\n",
            "| epoch   2 |   250/ 1600 steps | loss 1.51983 | ppl    4.571\n",
            "| epoch   2 |   300/ 1600 steps | loss 1.29656 | ppl    3.657\n",
            "| epoch   2 |   350/ 1600 steps | loss 0.98758 | ppl    2.685\n",
            "| epoch   2 |   400/ 1600 steps | loss 1.74231 | ppl    5.710\n",
            "| epoch   2 |   450/ 1600 steps | loss 1.19719 | ppl    3.311\n",
            "| epoch   2 |   500/ 1600 steps | loss 1.40211 | ppl    4.064\n",
            "| epoch   2 |   550/ 1600 steps | loss 1.48371 | ppl    4.409\n",
            "| epoch   2 |   600/ 1600 steps | loss 1.35642 | ppl    3.882\n",
            "| epoch   2 |   650/ 1600 steps | loss 1.50366 | ppl    4.498\n",
            "| epoch   2 |   700/ 1600 steps | loss 0.90169 | ppl    2.464\n",
            "| epoch   2 |   750/ 1600 steps | loss 1.87350 | ppl    6.511\n",
            "| epoch   2 |   800/ 1600 steps | loss 1.10800 | ppl    3.028\n",
            "| epoch   2 |   850/ 1600 steps | loss 1.19660 | ppl    3.309\n",
            "| epoch   2 |   900/ 1600 steps | loss 1.18388 | ppl    3.267\n",
            "| epoch   2 |   950/ 1600 steps | loss 1.53103 | ppl    4.623\n",
            "| epoch   2 |  1000/ 1600 steps | loss 1.53214 | ppl    4.628\n",
            "| epoch   2 |  1050/ 1600 steps | loss 1.02525 | ppl    2.788\n",
            "| epoch   2 |  1100/ 1600 steps | loss 0.83298 | ppl    2.300\n",
            "| epoch   2 |  1150/ 1600 steps | loss 1.43816 | ppl    4.213\n",
            "| epoch   2 |  1200/ 1600 steps | loss 1.23259 | ppl    3.430\n",
            "| epoch   2 |  1250/ 1600 steps | loss 1.29873 | ppl    3.665\n",
            "| epoch   2 |  1300/ 1600 steps | loss 1.58351 | ppl    4.872\n",
            "| epoch   2 |  1350/ 1600 steps | loss 0.92585 | ppl    2.524\n",
            "| epoch   2 |  1400/ 1600 steps | loss 1.09664 | ppl    2.994\n",
            "| epoch   2 |  1450/ 1600 steps | loss 1.02457 | ppl    2.786\n",
            "| epoch   2 |  1500/ 1600 steps | loss 1.37348 | ppl    3.949\n",
            "| epoch   2 |  1550/ 1600 steps | loss 1.71461 | ppl    5.554\n",
            "from_scratch=True - VALIDATION ACCURACY 0.671\n",
            "| epoch   3 |    50/ 1600 steps | loss 1.39475 | ppl    4.034\n",
            "| epoch   3 |   100/ 1600 steps | loss 0.93103 | ppl    2.537\n",
            "| epoch   3 |   150/ 1600 steps | loss 0.62288 | ppl    1.864\n",
            "| epoch   3 |   200/ 1600 steps | loss 1.23740 | ppl    3.447\n",
            "| epoch   3 |   250/ 1600 steps | loss 0.50551 | ppl    1.658\n",
            "| epoch   3 |   300/ 1600 steps | loss 1.04945 | ppl    2.856\n",
            "| epoch   3 |   350/ 1600 steps | loss 0.64481 | ppl    1.906\n",
            "| epoch   3 |   400/ 1600 steps | loss 0.69972 | ppl    2.013\n",
            "| epoch   3 |   450/ 1600 steps | loss 0.81183 | ppl    2.252\n",
            "| epoch   3 |   500/ 1600 steps | loss 0.59927 | ppl    1.821\n",
            "| epoch   3 |   550/ 1600 steps | loss 1.16921 | ppl    3.219\n",
            "| epoch   3 |   600/ 1600 steps | loss 0.69736 | ppl    2.008\n",
            "| epoch   3 |   650/ 1600 steps | loss 0.94151 | ppl    2.564\n",
            "| epoch   3 |   700/ 1600 steps | loss 0.93945 | ppl    2.559\n",
            "| epoch   3 |   750/ 1600 steps | loss 1.39674 | ppl    4.042\n",
            "| epoch   3 |   800/ 1600 steps | loss 0.31714 | ppl    1.373\n",
            "| epoch   3 |   850/ 1600 steps | loss 0.64717 | ppl    1.910\n",
            "| epoch   3 |   900/ 1600 steps | loss 0.82309 | ppl    2.278\n",
            "| epoch   3 |   950/ 1600 steps | loss 0.86654 | ppl    2.379\n",
            "| epoch   3 |  1000/ 1600 steps | loss 0.48112 | ppl    1.618\n",
            "| epoch   3 |  1050/ 1600 steps | loss 0.45245 | ppl    1.572\n",
            "| epoch   3 |  1100/ 1600 steps | loss 0.90455 | ppl    2.471\n",
            "| epoch   3 |  1150/ 1600 steps | loss 0.71840 | ppl    2.051\n",
            "| epoch   3 |  1200/ 1600 steps | loss 0.64279 | ppl    1.902\n",
            "| epoch   3 |  1250/ 1600 steps | loss 0.82977 | ppl    2.293\n",
            "| epoch   3 |  1300/ 1600 steps | loss 0.52096 | ppl    1.684\n",
            "| epoch   3 |  1350/ 1600 steps | loss 0.89811 | ppl    2.455\n",
            "| epoch   3 |  1400/ 1600 steps | loss 0.53450 | ppl    1.707\n",
            "| epoch   3 |  1450/ 1600 steps | loss 0.80865 | ppl    2.245\n",
            "| epoch   3 |  1500/ 1600 steps | loss 0.57764 | ppl    1.782\n",
            "| epoch   3 |  1550/ 1600 steps | loss 0.68723 | ppl    1.988\n",
            "from_scratch=True - VALIDATION ACCURACY 0.6765\n",
            "| epoch   4 |    50/ 1600 steps | loss 0.30858 | ppl    1.361\n",
            "| epoch   4 |   100/ 1600 steps | loss 0.20520 | ppl    1.228\n",
            "| epoch   4 |   150/ 1600 steps | loss 0.23759 | ppl    1.268\n",
            "| epoch   4 |   200/ 1600 steps | loss 0.23142 | ppl    1.260\n",
            "| epoch   4 |   250/ 1600 steps | loss 0.59961 | ppl    1.821\n",
            "| epoch   4 |   300/ 1600 steps | loss 0.27215 | ppl    1.313\n",
            "| epoch   4 |   350/ 1600 steps | loss 0.07003 | ppl    1.073\n",
            "| epoch   4 |   400/ 1600 steps | loss 0.00587 | ppl    1.006\n",
            "| epoch   4 |   450/ 1600 steps | loss 0.09514 | ppl    1.100\n",
            "| epoch   4 |   500/ 1600 steps | loss 0.13260 | ppl    1.142\n",
            "| epoch   4 |   550/ 1600 steps | loss 0.14672 | ppl    1.158\n",
            "| epoch   4 |   600/ 1600 steps | loss 0.88831 | ppl    2.431\n",
            "| epoch   4 |   650/ 1600 steps | loss 0.41103 | ppl    1.508\n",
            "| epoch   4 |   700/ 1600 steps | loss 0.14061 | ppl    1.151\n",
            "| epoch   4 |   750/ 1600 steps | loss 0.19409 | ppl    1.214\n",
            "| epoch   4 |   800/ 1600 steps | loss 0.23527 | ppl    1.265\n",
            "| epoch   4 |   850/ 1600 steps | loss 0.15717 | ppl    1.170\n",
            "| epoch   4 |   900/ 1600 steps | loss 0.44362 | ppl    1.558\n",
            "| epoch   4 |   950/ 1600 steps | loss 0.04215 | ppl    1.043\n",
            "| epoch   4 |  1000/ 1600 steps | loss 0.26444 | ppl    1.303\n",
            "| epoch   4 |  1050/ 1600 steps | loss 0.45983 | ppl    1.584\n",
            "| epoch   4 |  1100/ 1600 steps | loss 0.19812 | ppl    1.219\n",
            "| epoch   4 |  1150/ 1600 steps | loss 0.55967 | ppl    1.750\n",
            "| epoch   4 |  1200/ 1600 steps | loss 0.13444 | ppl    1.144\n",
            "| epoch   4 |  1250/ 1600 steps | loss 0.00053 | ppl    1.001\n",
            "| epoch   4 |  1300/ 1600 steps | loss 0.10040 | ppl    1.106\n",
            "| epoch   4 |  1350/ 1600 steps | loss 0.20894 | ppl    1.232\n",
            "| epoch   4 |  1400/ 1600 steps | loss 0.19374 | ppl    1.214\n",
            "| epoch   4 |  1450/ 1600 steps | loss 0.10019 | ppl    1.105\n",
            "| epoch   4 |  1500/ 1600 steps | loss 0.41360 | ppl    1.512\n",
            "| epoch   4 |  1550/ 1600 steps | loss 0.21293 | ppl    1.237\n",
            "from_scratch=True - VALIDATION ACCURACY 0.7325\n",
            "| epoch   5 |    50/ 1600 steps | loss 0.00022 | ppl    1.000\n",
            "| epoch   5 |   100/ 1600 steps | loss 0.00032 | ppl    1.000\n",
            "| epoch   5 |   150/ 1600 steps | loss 0.00009 | ppl    1.000\n",
            "| epoch   5 |   200/ 1600 steps | loss 0.12896 | ppl    1.138\n",
            "| epoch   5 |   250/ 1600 steps | loss 0.00008 | ppl    1.000\n",
            "| epoch   5 |   300/ 1600 steps | loss 0.00016 | ppl    1.000\n",
            "| epoch   5 |   350/ 1600 steps | loss 0.00004 | ppl    1.000\n",
            "| epoch   5 |   400/ 1600 steps | loss 0.23200 | ppl    1.261\n",
            "| epoch   5 |   450/ 1600 steps | loss 0.08419 | ppl    1.088\n",
            "| epoch   5 |   500/ 1600 steps | loss 0.00006 | ppl    1.000\n",
            "| epoch   5 |   550/ 1600 steps | loss 0.20381 | ppl    1.226\n",
            "| epoch   5 |   600/ 1600 steps | loss 0.00010 | ppl    1.000\n",
            "| epoch   5 |   650/ 1600 steps | loss 0.00009 | ppl    1.000\n",
            "| epoch   5 |   700/ 1600 steps | loss 0.00006 | ppl    1.000\n",
            "| epoch   5 |   750/ 1600 steps | loss 0.00016 | ppl    1.000\n",
            "| epoch   5 |   800/ 1600 steps | loss 0.00006 | ppl    1.000\n",
            "| epoch   5 |   850/ 1600 steps | loss 0.00003 | ppl    1.000\n",
            "| epoch   5 |   900/ 1600 steps | loss 0.00003 | ppl    1.000\n",
            "| epoch   5 |   950/ 1600 steps | loss 0.18506 | ppl    1.203\n",
            "| epoch   5 |  1000/ 1600 steps | loss 0.00003 | ppl    1.000\n",
            "| epoch   5 |  1050/ 1600 steps | loss 0.00181 | ppl    1.002\n",
            "| epoch   5 |  1100/ 1600 steps | loss 0.00002 | ppl    1.000\n",
            "| epoch   5 |  1150/ 1600 steps | loss 0.00002 | ppl    1.000\n",
            "| epoch   5 |  1200/ 1600 steps | loss 0.00002 | ppl    1.000\n",
            "| epoch   5 |  1250/ 1600 steps | loss 0.00002 | ppl    1.000\n",
            "| epoch   5 |  1300/ 1600 steps | loss 0.14746 | ppl    1.159\n",
            "| epoch   5 |  1350/ 1600 steps | loss 0.00002 | ppl    1.000\n",
            "| epoch   5 |  1400/ 1600 steps | loss 0.24048 | ppl    1.272\n",
            "| epoch   5 |  1450/ 1600 steps | loss 0.40202 | ppl    1.495\n",
            "| epoch   5 |  1500/ 1600 steps | loss 0.09575 | ppl    1.100\n",
            "| epoch   5 |  1550/ 1600 steps | loss 0.31654 | ppl    1.372\n",
            "from_scratch=True - VALIDATION ACCURACY 0.6925\n",
            "| epoch   6 |    50/ 1600 steps | loss 0.00016 | ppl    1.000\n",
            "| epoch   6 |   100/ 1600 steps | loss 0.40454 | ppl    1.499\n",
            "| epoch   6 |   150/ 1600 steps | loss 0.34228 | ppl    1.408\n",
            "| epoch   6 |   200/ 1600 steps | loss 0.00018 | ppl    1.000\n",
            "| epoch   6 |   250/ 1600 steps | loss 0.00008 | ppl    1.000\n",
            "| epoch   6 |   300/ 1600 steps | loss 0.04230 | ppl    1.043\n",
            "| epoch   6 |   350/ 1600 steps | loss 0.00005 | ppl    1.000\n",
            "| epoch   6 |   400/ 1600 steps | loss 0.00004 | ppl    1.000\n",
            "| epoch   6 |   450/ 1600 steps | loss 0.00006 | ppl    1.000\n",
            "| epoch   6 |   500/ 1600 steps | loss 0.11989 | ppl    1.127\n",
            "| epoch   6 |   550/ 1600 steps | loss 0.00004 | ppl    1.000\n",
            "| epoch   6 |   600/ 1600 steps | loss 0.14454 | ppl    1.156\n",
            "| epoch   6 |   650/ 1600 steps | loss 0.00002 | ppl    1.000\n",
            "| epoch   6 |   700/ 1600 steps | loss 0.00002 | ppl    1.000\n",
            "| epoch   6 |   750/ 1600 steps | loss 0.00002 | ppl    1.000\n",
            "| epoch   6 |   800/ 1600 steps | loss 0.00002 | ppl    1.000\n",
            "| epoch   6 |   850/ 1600 steps | loss 0.19131 | ppl    1.211\n",
            "| epoch   6 |   900/ 1600 steps | loss 0.00020 | ppl    1.000\n",
            "| epoch   6 |   950/ 1600 steps | loss 0.00012 | ppl    1.000\n",
            "| epoch   6 |  1000/ 1600 steps | loss 0.00002 | ppl    1.000\n",
            "| epoch   6 |  1050/ 1600 steps | loss 0.20719 | ppl    1.230\n",
            "| epoch   6 |  1100/ 1600 steps | loss 0.12093 | ppl    1.129\n",
            "| epoch   6 |  1150/ 1600 steps | loss 0.00035 | ppl    1.000\n",
            "| epoch   6 |  1200/ 1600 steps | loss 0.24181 | ppl    1.274\n",
            "| epoch   6 |  1250/ 1600 steps | loss 0.14811 | ppl    1.160\n",
            "| epoch   6 |  1300/ 1600 steps | loss 0.00006 | ppl    1.000\n",
            "| epoch   6 |  1350/ 1600 steps | loss 0.00021 | ppl    1.000\n",
            "| epoch   6 |  1400/ 1600 steps | loss 0.00004 | ppl    1.000\n",
            "| epoch   6 |  1450/ 1600 steps | loss 0.00003 | ppl    1.000\n",
            "| epoch   6 |  1500/ 1600 steps | loss 0.43777 | ppl    1.549\n",
            "| epoch   6 |  1550/ 1600 steps | loss 0.23578 | ppl    1.266\n",
            "from_scratch=True - VALIDATION ACCURACY 0.73\n",
            "| epoch   7 |    50/ 1600 steps | loss 0.00006 | ppl    1.000\n",
            "| epoch   7 |   100/ 1600 steps | loss 0.00004 | ppl    1.000\n",
            "| epoch   7 |   150/ 1600 steps | loss 0.00003 | ppl    1.000\n",
            "| epoch   7 |   200/ 1600 steps | loss 0.00003 | ppl    1.000\n",
            "| epoch   7 |   250/ 1600 steps | loss 0.00002 | ppl    1.000\n",
            "| epoch   7 |   300/ 1600 steps | loss 0.00003 | ppl    1.000\n",
            "| epoch   7 |   350/ 1600 steps | loss 0.00002 | ppl    1.000\n",
            "| epoch   7 |   400/ 1600 steps | loss 0.00002 | ppl    1.000\n",
            "| epoch   7 |   450/ 1600 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch   7 |   500/ 1600 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch   7 |   550/ 1600 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch   7 |   600/ 1600 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch   7 |   650/ 1600 steps | loss 0.15106 | ppl    1.163\n",
            "| epoch   7 |   700/ 1600 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch   7 |   750/ 1600 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch   7 |   800/ 1600 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch   7 |   850/ 1600 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch   7 |   900/ 1600 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch   7 |   950/ 1600 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch   7 |  1000/ 1600 steps | loss 0.48727 | ppl    1.628\n",
            "| epoch   7 |  1050/ 1600 steps | loss 0.16416 | ppl    1.178\n",
            "| epoch   7 |  1100/ 1600 steps | loss 0.64638 | ppl    1.909\n",
            "| epoch   7 |  1150/ 1600 steps | loss 0.00063 | ppl    1.001\n",
            "| epoch   7 |  1200/ 1600 steps | loss 0.00005 | ppl    1.000\n",
            "| epoch   7 |  1250/ 1600 steps | loss 0.00004 | ppl    1.000\n",
            "| epoch   7 |  1300/ 1600 steps | loss 0.00003 | ppl    1.000\n",
            "| epoch   7 |  1350/ 1600 steps | loss 0.00003 | ppl    1.000\n",
            "| epoch   7 |  1400/ 1600 steps | loss 0.00003 | ppl    1.000\n",
            "| epoch   7 |  1450/ 1600 steps | loss 0.00002 | ppl    1.000\n",
            "| epoch   7 |  1500/ 1600 steps | loss 0.00002 | ppl    1.000\n",
            "| epoch   7 |  1550/ 1600 steps | loss 0.28486 | ppl    1.330\n",
            "from_scratch=True - VALIDATION ACCURACY 0.732\n",
            "| epoch   8 |    50/ 1600 steps | loss 0.00002 | ppl    1.000\n",
            "| epoch   8 |   100/ 1600 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch   8 |   150/ 1600 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch   8 |   200/ 1600 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch   8 |   250/ 1600 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch   8 |   300/ 1600 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch   8 |   350/ 1600 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch   8 |   400/ 1600 steps | loss 0.30637 | ppl    1.358\n",
            "| epoch   8 |   450/ 1600 steps | loss 0.00002 | ppl    1.000\n",
            "| epoch   8 |   500/ 1600 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch   8 |   550/ 1600 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch   8 |   600/ 1600 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch   8 |   650/ 1600 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch   8 |   700/ 1600 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch   8 |   750/ 1600 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch   8 |   800/ 1600 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch   8 |   850/ 1600 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch   8 |   900/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch   8 |   950/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch   8 |  1000/ 1600 steps | loss 0.05278 | ppl    1.054\n",
            "| epoch   8 |  1050/ 1600 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch   8 |  1100/ 1600 steps | loss 0.00008 | ppl    1.000\n",
            "| epoch   8 |  1150/ 1600 steps | loss 0.00003 | ppl    1.000\n",
            "| epoch   8 |  1200/ 1600 steps | loss 0.22779 | ppl    1.256\n",
            "| epoch   8 |  1250/ 1600 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch   8 |  1300/ 1600 steps | loss 0.36604 | ppl    1.442\n",
            "| epoch   8 |  1350/ 1600 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch   8 |  1400/ 1600 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch   8 |  1450/ 1600 steps | loss 0.00002 | ppl    1.000\n",
            "| epoch   8 |  1500/ 1600 steps | loss 0.12114 | ppl    1.129\n",
            "| epoch   8 |  1550/ 1600 steps | loss 0.15117 | ppl    1.163\n",
            "from_scratch=True - VALIDATION ACCURACY 0.666\n",
            "| epoch   9 |    50/ 1600 steps | loss 0.18140 | ppl    1.199\n",
            "| epoch   9 |   100/ 1600 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch   9 |   150/ 1600 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch   9 |   200/ 1600 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch   9 |   250/ 1600 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch   9 |   300/ 1600 steps | loss 0.12020 | ppl    1.128\n",
            "| epoch   9 |   350/ 1600 steps | loss 0.00002 | ppl    1.000\n",
            "| epoch   9 |   400/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch   9 |   450/ 1600 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch   9 |   500/ 1600 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch   9 |   550/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch   9 |   600/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch   9 |   650/ 1600 steps | loss 0.00310 | ppl    1.003\n",
            "| epoch   9 |   700/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch   9 |   750/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch   9 |   800/ 1600 steps | loss 0.16200 | ppl    1.176\n",
            "| epoch   9 |   850/ 1600 steps | loss 0.05523 | ppl    1.057\n",
            "| epoch   9 |   900/ 1600 steps | loss 0.04325 | ppl    1.044\n",
            "| epoch   9 |   950/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch   9 |  1000/ 1600 steps | loss 0.24017 | ppl    1.271\n",
            "| epoch   9 |  1050/ 1600 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch   9 |  1100/ 1600 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch   9 |  1150/ 1600 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch   9 |  1200/ 1600 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch   9 |  1250/ 1600 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch   9 |  1300/ 1600 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch   9 |  1350/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch   9 |  1400/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch   9 |  1450/ 1600 steps | loss 0.01010 | ppl    1.010\n",
            "| epoch   9 |  1500/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch   9 |  1550/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "from_scratch=True - VALIDATION ACCURACY 0.7405\n",
            "| epoch  10 |    50/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  10 |   100/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  10 |   150/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  10 |   200/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  10 |   250/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  10 |   300/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  10 |   350/ 1600 steps | loss 0.15550 | ppl    1.168\n",
            "| epoch  10 |   400/ 1600 steps | loss 0.00016 | ppl    1.000\n",
            "| epoch  10 |   450/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  10 |   500/ 1600 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  10 |   550/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  10 |   600/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  10 |   650/ 1600 steps | loss 0.33450 | ppl    1.397\n",
            "| epoch  10 |   700/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  10 |   750/ 1600 steps | loss 0.04100 | ppl    1.042\n",
            "| epoch  10 |   800/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  10 |   850/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  10 |   900/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  10 |   950/ 1600 steps | loss 0.00005 | ppl    1.000\n",
            "| epoch  10 |  1000/ 1600 steps | loss 0.18471 | ppl    1.203\n",
            "| epoch  10 |  1050/ 1600 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  10 |  1100/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  10 |  1150/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  10 |  1200/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  10 |  1250/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  10 |  1300/ 1600 steps | loss 0.09645 | ppl    1.101\n",
            "| epoch  10 |  1350/ 1600 steps | loss 0.18445 | ppl    1.203\n",
            "| epoch  10 |  1400/ 1600 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  10 |  1450/ 1600 steps | loss 0.14156 | ppl    1.152\n",
            "| epoch  10 |  1500/ 1600 steps | loss 0.21155 | ppl    1.236\n",
            "| epoch  10 |  1550/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "from_scratch=True - VALIDATION ACCURACY 0.715\n",
            "| epoch  11 |    50/ 1600 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  11 |   100/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  11 |   150/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  11 |   200/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  11 |   250/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  11 |   300/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  11 |   350/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  11 |   400/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  11 |   450/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  11 |   500/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  11 |   550/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  11 |   600/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  11 |   650/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  11 |   700/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  11 |   750/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  11 |   800/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  11 |   850/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  11 |   900/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  11 |   950/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  11 |  1000/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  11 |  1050/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  11 |  1100/ 1600 steps | loss 0.00007 | ppl    1.000\n",
            "| epoch  11 |  1150/ 1600 steps | loss 0.24405 | ppl    1.276\n",
            "| epoch  11 |  1200/ 1600 steps | loss 0.18906 | ppl    1.208\n",
            "| epoch  11 |  1250/ 1600 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  11 |  1300/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  11 |  1350/ 1600 steps | loss 0.06020 | ppl    1.062\n",
            "| epoch  11 |  1400/ 1600 steps | loss 0.01619 | ppl    1.016\n",
            "| epoch  11 |  1450/ 1600 steps | loss 0.65648 | ppl    1.928\n",
            "| epoch  11 |  1500/ 1600 steps | loss 0.00005 | ppl    1.000\n",
            "| epoch  11 |  1550/ 1600 steps | loss 0.00699 | ppl    1.007\n",
            "from_scratch=True - VALIDATION ACCURACY 0.7475\n",
            "| epoch  12 |    50/ 1600 steps | loss 0.00003 | ppl    1.000\n",
            "| epoch  12 |   100/ 1600 steps | loss 0.00003 | ppl    1.000\n",
            "| epoch  12 |   150/ 1600 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  12 |   200/ 1600 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  12 |   250/ 1600 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  12 |   300/ 1600 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  12 |   350/ 1600 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  12 |   400/ 1600 steps | loss 0.00010 | ppl    1.000\n",
            "| epoch  12 |   450/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  12 |   500/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  12 |   550/ 1600 steps | loss 0.29546 | ppl    1.344\n",
            "| epoch  12 |   600/ 1600 steps | loss 0.00002 | ppl    1.000\n",
            "| epoch  12 |   650/ 1600 steps | loss 0.06442 | ppl    1.067\n",
            "| epoch  12 |   700/ 1600 steps | loss 0.08036 | ppl    1.084\n",
            "| epoch  12 |   750/ 1600 steps | loss 0.01719 | ppl    1.017\n",
            "| epoch  12 |   800/ 1600 steps | loss 0.13549 | ppl    1.145\n",
            "| epoch  12 |   850/ 1600 steps | loss 0.00540 | ppl    1.005\n",
            "| epoch  12 |   900/ 1600 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  12 |   950/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  12 |  1000/ 1600 steps | loss 0.00003 | ppl    1.000\n",
            "| epoch  12 |  1050/ 1600 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  12 |  1100/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  12 |  1150/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  12 |  1200/ 1600 steps | loss 0.07775 | ppl    1.081\n",
            "| epoch  12 |  1250/ 1600 steps | loss 0.18112 | ppl    1.199\n",
            "| epoch  12 |  1300/ 1600 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  12 |  1350/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  12 |  1400/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  12 |  1450/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  12 |  1500/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  12 |  1550/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "from_scratch=True - VALIDATION ACCURACY 0.738\n",
            "| epoch  13 |    50/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  13 |   100/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  13 |   150/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  13 |   200/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  13 |   250/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  13 |   300/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  13 |   350/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  13 |   400/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  13 |   450/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  13 |   500/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  13 |   550/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  13 |   600/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  13 |   650/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  13 |   700/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  13 |   750/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  13 |   800/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  13 |   850/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  13 |   900/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  13 |   950/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  13 |  1000/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  13 |  1050/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  13 |  1100/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  13 |  1150/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  13 |  1200/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  13 |  1250/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  13 |  1300/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  13 |  1350/ 1600 steps | loss 0.00003 | ppl    1.000\n",
            "| epoch  13 |  1400/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  13 |  1450/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  13 |  1500/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  13 |  1550/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "from_scratch=True - VALIDATION ACCURACY 0.753\n",
            "| epoch  14 |    50/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  14 |   100/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  14 |   150/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  14 |   200/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  14 |   250/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  14 |   300/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  14 |   350/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  14 |   400/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  14 |   450/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  14 |   500/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  14 |   550/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  14 |   600/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  14 |   650/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  14 |   700/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  14 |   750/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  14 |   800/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  14 |   850/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  14 |   900/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  14 |   950/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  14 |  1000/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  14 |  1050/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  14 |  1100/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  14 |  1150/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  14 |  1200/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  14 |  1250/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  14 |  1300/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  14 |  1350/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  14 |  1400/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  14 |  1450/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  14 |  1500/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  14 |  1550/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "from_scratch=True - VALIDATION ACCURACY 0.75\n",
            "| epoch  15 |    50/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  15 |   100/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  15 |   150/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  15 |   200/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  15 |   250/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  15 |   300/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  15 |   350/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  15 |   400/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  15 |   450/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  15 |   500/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  15 |   550/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  15 |   600/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  15 |   650/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  15 |   700/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  15 |   750/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  15 |   800/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  15 |   850/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  15 |   900/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  15 |   950/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  15 |  1000/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  15 |  1050/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  15 |  1100/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  15 |  1150/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  15 |  1200/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  15 |  1250/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  15 |  1300/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  15 |  1350/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  15 |  1400/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  15 |  1450/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  15 |  1500/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  15 |  1550/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "from_scratch=True - VALIDATION ACCURACY 0.7505\n",
            "=====PRETRAINED MODEL======\n",
            "| epoch   1 |    50/ 1600 steps | loss 2.71881 | ppl   15.162\n",
            "| epoch   1 |   100/ 1600 steps | loss 1.25289 | ppl    3.500\n",
            "| epoch   1 |   150/ 1600 steps | loss 1.74467 | ppl    5.724\n",
            "| epoch   1 |   200/ 1600 steps | loss 1.65929 | ppl    5.256\n",
            "| epoch   1 |   250/ 1600 steps | loss 1.30780 | ppl    3.698\n",
            "| epoch   1 |   300/ 1600 steps | loss 1.01788 | ppl    2.767\n",
            "| epoch   1 |   350/ 1600 steps | loss 1.27821 | ppl    3.590\n",
            "| epoch   1 |   400/ 1600 steps | loss 1.29064 | ppl    3.635\n",
            "| epoch   1 |   450/ 1600 steps | loss 1.15958 | ppl    3.189\n",
            "| epoch   1 |   500/ 1600 steps | loss 0.71722 | ppl    2.049\n",
            "| epoch   1 |   550/ 1600 steps | loss 0.98508 | ppl    2.678\n",
            "| epoch   1 |   600/ 1600 steps | loss 0.72585 | ppl    2.066\n",
            "| epoch   1 |   650/ 1600 steps | loss 1.50067 | ppl    4.485\n",
            "| epoch   1 |   700/ 1600 steps | loss 1.89259 | ppl    6.637\n",
            "| epoch   1 |   750/ 1600 steps | loss 0.73233 | ppl    2.080\n",
            "| epoch   1 |   800/ 1600 steps | loss 0.94550 | ppl    2.574\n",
            "| epoch   1 |   850/ 1600 steps | loss 1.00434 | ppl    2.730\n",
            "| epoch   1 |   900/ 1600 steps | loss 1.30444 | ppl    3.686\n",
            "| epoch   1 |   950/ 1600 steps | loss 0.81870 | ppl    2.268\n",
            "| epoch   1 |  1000/ 1600 steps | loss 0.94788 | ppl    2.580\n",
            "| epoch   1 |  1050/ 1600 steps | loss 1.44969 | ppl    4.262\n",
            "| epoch   1 |  1100/ 1600 steps | loss 0.93656 | ppl    2.551\n",
            "| epoch   1 |  1150/ 1600 steps | loss 1.87523 | ppl    6.522\n",
            "| epoch   1 |  1200/ 1600 steps | loss 1.43954 | ppl    4.219\n",
            "| epoch   1 |  1250/ 1600 steps | loss 1.00450 | ppl    2.731\n",
            "| epoch   1 |  1300/ 1600 steps | loss 1.53006 | ppl    4.618\n",
            "| epoch   1 |  1350/ 1600 steps | loss 1.41914 | ppl    4.134\n",
            "| epoch   1 |  1400/ 1600 steps | loss 1.78471 | ppl    5.958\n",
            "| epoch   1 |  1450/ 1600 steps | loss 0.98482 | ppl    2.677\n",
            "| epoch   1 |  1500/ 1600 steps | loss 0.56103 | ppl    1.752\n",
            "| epoch   1 |  1550/ 1600 steps | loss 0.92914 | ppl    2.532\n",
            "from_scratch=False - VALIDATION ACCURACY 0.755\n",
            "| epoch   2 |    50/ 1600 steps | loss 0.35081 | ppl    1.420\n",
            "| epoch   2 |   100/ 1600 steps | loss 0.64518 | ppl    1.906\n",
            "| epoch   2 |   150/ 1600 steps | loss 0.38713 | ppl    1.473\n",
            "| epoch   2 |   200/ 1600 steps | loss 0.72491 | ppl    2.065\n",
            "| epoch   2 |   250/ 1600 steps | loss 0.62415 | ppl    1.867\n",
            "| epoch   2 |   300/ 1600 steps | loss 0.69415 | ppl    2.002\n",
            "| epoch   2 |   350/ 1600 steps | loss 1.14606 | ppl    3.146\n",
            "| epoch   2 |   400/ 1600 steps | loss 0.42133 | ppl    1.524\n",
            "| epoch   2 |   450/ 1600 steps | loss 0.68587 | ppl    1.985\n",
            "| epoch   2 |   500/ 1600 steps | loss 0.61652 | ppl    1.852\n",
            "| epoch   2 |   550/ 1600 steps | loss 0.60642 | ppl    1.834\n",
            "| epoch   2 |   600/ 1600 steps | loss 0.80675 | ppl    2.241\n",
            "| epoch   2 |   650/ 1600 steps | loss 0.08188 | ppl    1.085\n",
            "| epoch   2 |   700/ 1600 steps | loss 0.94698 | ppl    2.578\n",
            "| epoch   2 |   750/ 1600 steps | loss 1.55982 | ppl    4.758\n",
            "| epoch   2 |   800/ 1600 steps | loss 0.55740 | ppl    1.746\n",
            "| epoch   2 |   850/ 1600 steps | loss 0.71227 | ppl    2.039\n",
            "| epoch   2 |   900/ 1600 steps | loss 0.58478 | ppl    1.795\n",
            "| epoch   2 |   950/ 1600 steps | loss 0.78617 | ppl    2.195\n",
            "| epoch   2 |  1000/ 1600 steps | loss 0.76329 | ppl    2.145\n",
            "| epoch   2 |  1050/ 1600 steps | loss 0.84736 | ppl    2.333\n",
            "| epoch   2 |  1100/ 1600 steps | loss 0.52431 | ppl    1.689\n",
            "| epoch   2 |  1150/ 1600 steps | loss 0.40571 | ppl    1.500\n",
            "| epoch   2 |  1200/ 1600 steps | loss 1.11610 | ppl    3.053\n",
            "| epoch   2 |  1250/ 1600 steps | loss 0.68141 | ppl    1.977\n",
            "| epoch   2 |  1300/ 1600 steps | loss 0.31315 | ppl    1.368\n",
            "| epoch   2 |  1350/ 1600 steps | loss 0.65768 | ppl    1.930\n",
            "| epoch   2 |  1400/ 1600 steps | loss 1.30245 | ppl    3.678\n",
            "| epoch   2 |  1450/ 1600 steps | loss 0.27716 | ppl    1.319\n",
            "| epoch   2 |  1500/ 1600 steps | loss 0.43001 | ppl    1.537\n",
            "| epoch   2 |  1550/ 1600 steps | loss 1.32077 | ppl    3.746\n",
            "from_scratch=False - VALIDATION ACCURACY 0.7485\n",
            "| epoch   3 |    50/ 1600 steps | loss 0.31749 | ppl    1.374\n",
            "| epoch   3 |   100/ 1600 steps | loss 0.37663 | ppl    1.457\n",
            "| epoch   3 |   150/ 1600 steps | loss 0.00093 | ppl    1.001\n",
            "| epoch   3 |   200/ 1600 steps | loss 0.57475 | ppl    1.777\n",
            "| epoch   3 |   250/ 1600 steps | loss 0.47108 | ppl    1.602\n",
            "| epoch   3 |   300/ 1600 steps | loss 0.31983 | ppl    1.377\n",
            "| epoch   3 |   350/ 1600 steps | loss 0.16060 | ppl    1.174\n",
            "| epoch   3 |   400/ 1600 steps | loss 0.66188 | ppl    1.938\n",
            "| epoch   3 |   450/ 1600 steps | loss 0.20194 | ppl    1.224\n",
            "| epoch   3 |   500/ 1600 steps | loss 0.30270 | ppl    1.354\n",
            "| epoch   3 |   550/ 1600 steps | loss 0.48535 | ppl    1.625\n",
            "| epoch   3 |   600/ 1600 steps | loss 0.25634 | ppl    1.292\n",
            "| epoch   3 |   650/ 1600 steps | loss 0.38197 | ppl    1.465\n",
            "| epoch   3 |   700/ 1600 steps | loss 0.84009 | ppl    2.317\n",
            "| epoch   3 |   750/ 1600 steps | loss 0.09429 | ppl    1.099\n",
            "| epoch   3 |   800/ 1600 steps | loss 0.10829 | ppl    1.114\n",
            "| epoch   3 |   850/ 1600 steps | loss 0.43598 | ppl    1.546\n",
            "| epoch   3 |   900/ 1600 steps | loss 0.19196 | ppl    1.212\n",
            "| epoch   3 |   950/ 1600 steps | loss 0.39989 | ppl    1.492\n",
            "| epoch   3 |  1000/ 1600 steps | loss 0.46227 | ppl    1.588\n",
            "| epoch   3 |  1050/ 1600 steps | loss 0.42946 | ppl    1.536\n",
            "| epoch   3 |  1100/ 1600 steps | loss 0.26893 | ppl    1.309\n",
            "| epoch   3 |  1150/ 1600 steps | loss 0.09058 | ppl    1.095\n",
            "| epoch   3 |  1200/ 1600 steps | loss 0.21039 | ppl    1.234\n",
            "| epoch   3 |  1250/ 1600 steps | loss 0.00090 | ppl    1.001\n",
            "| epoch   3 |  1300/ 1600 steps | loss 0.36849 | ppl    1.446\n",
            "| epoch   3 |  1350/ 1600 steps | loss 0.23400 | ppl    1.264\n",
            "| epoch   3 |  1400/ 1600 steps | loss 0.43520 | ppl    1.545\n",
            "| epoch   3 |  1450/ 1600 steps | loss 0.30182 | ppl    1.352\n",
            "| epoch   3 |  1500/ 1600 steps | loss 0.00821 | ppl    1.008\n",
            "| epoch   3 |  1550/ 1600 steps | loss 0.00535 | ppl    1.005\n",
            "from_scratch=False - VALIDATION ACCURACY 0.7675\n",
            "| epoch   4 |    50/ 1600 steps | loss 0.01188 | ppl    1.012\n",
            "| epoch   4 |   100/ 1600 steps | loss 0.00003 | ppl    1.000\n",
            "| epoch   4 |   150/ 1600 steps | loss 0.15616 | ppl    1.169\n",
            "| epoch   4 |   200/ 1600 steps | loss 0.00003 | ppl    1.000\n",
            "| epoch   4 |   250/ 1600 steps | loss 0.00258 | ppl    1.003\n",
            "| epoch   4 |   300/ 1600 steps | loss 0.23046 | ppl    1.259\n",
            "| epoch   4 |   350/ 1600 steps | loss 0.02636 | ppl    1.027\n",
            "| epoch   4 |   400/ 1600 steps | loss 0.21446 | ppl    1.239\n",
            "| epoch   4 |   450/ 1600 steps | loss 0.00059 | ppl    1.001\n",
            "| epoch   4 |   500/ 1600 steps | loss 0.06399 | ppl    1.066\n",
            "| epoch   4 |   550/ 1600 steps | loss 0.00002 | ppl    1.000\n",
            "| epoch   4 |   600/ 1600 steps | loss 0.00002 | ppl    1.000\n",
            "| epoch   4 |   650/ 1600 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch   4 |   700/ 1600 steps | loss 0.40384 | ppl    1.498\n",
            "| epoch   4 |   750/ 1600 steps | loss 0.09013 | ppl    1.094\n",
            "| epoch   4 |   800/ 1600 steps | loss 0.22216 | ppl    1.249\n",
            "| epoch   4 |   850/ 1600 steps | loss 0.00295 | ppl    1.003\n",
            "| epoch   4 |   900/ 1600 steps | loss 0.01723 | ppl    1.017\n",
            "| epoch   4 |   950/ 1600 steps | loss 0.00024 | ppl    1.000\n",
            "| epoch   4 |  1000/ 1600 steps | loss 0.14095 | ppl    1.151\n",
            "| epoch   4 |  1050/ 1600 steps | loss 0.00347 | ppl    1.003\n",
            "| epoch   4 |  1100/ 1600 steps | loss 0.01703 | ppl    1.017\n",
            "| epoch   4 |  1150/ 1600 steps | loss 0.22274 | ppl    1.249\n",
            "| epoch   4 |  1200/ 1600 steps | loss 0.47852 | ppl    1.614\n",
            "| epoch   4 |  1250/ 1600 steps | loss 0.25984 | ppl    1.297\n",
            "| epoch   4 |  1300/ 1600 steps | loss 0.00775 | ppl    1.008\n",
            "| epoch   4 |  1350/ 1600 steps | loss 0.09871 | ppl    1.104\n",
            "| epoch   4 |  1400/ 1600 steps | loss 0.09981 | ppl    1.105\n",
            "| epoch   4 |  1450/ 1600 steps | loss 0.03654 | ppl    1.037\n",
            "| epoch   4 |  1500/ 1600 steps | loss 0.22897 | ppl    1.257\n",
            "| epoch   4 |  1550/ 1600 steps | loss 0.16002 | ppl    1.174\n",
            "from_scratch=False - VALIDATION ACCURACY 0.724\n",
            "| epoch   5 |    50/ 1600 steps | loss 0.19570 | ppl    1.216\n",
            "| epoch   5 |   100/ 1600 steps | loss 0.00018 | ppl    1.000\n",
            "| epoch   5 |   150/ 1600 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch   5 |   200/ 1600 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch   5 |   250/ 1600 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch   5 |   300/ 1600 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch   5 |   350/ 1600 steps | loss 0.13789 | ppl    1.148\n",
            "| epoch   5 |   400/ 1600 steps | loss 0.14837 | ppl    1.160\n",
            "| epoch   5 |   450/ 1600 steps | loss 0.13460 | ppl    1.144\n",
            "| epoch   5 |   500/ 1600 steps | loss 0.00007 | ppl    1.000\n",
            "| epoch   5 |   550/ 1600 steps | loss 0.27330 | ppl    1.314\n",
            "| epoch   5 |   600/ 1600 steps | loss 0.20933 | ppl    1.233\n",
            "| epoch   5 |   650/ 1600 steps | loss 0.19616 | ppl    1.217\n",
            "| epoch   5 |   700/ 1600 steps | loss 0.26774 | ppl    1.307\n",
            "| epoch   5 |   750/ 1600 steps | loss 0.26190 | ppl    1.299\n",
            "| epoch   5 |   800/ 1600 steps | loss 0.01486 | ppl    1.015\n",
            "| epoch   5 |   850/ 1600 steps | loss 0.00173 | ppl    1.002\n",
            "| epoch   5 |   900/ 1600 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch   5 |   950/ 1600 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch   5 |  1000/ 1600 steps | loss 0.00313 | ppl    1.003\n",
            "| epoch   5 |  1050/ 1600 steps | loss 0.00023 | ppl    1.000\n",
            "| epoch   5 |  1100/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch   5 |  1150/ 1600 steps | loss 0.15084 | ppl    1.163\n",
            "| epoch   5 |  1200/ 1600 steps | loss 0.00745 | ppl    1.007\n",
            "| epoch   5 |  1250/ 1600 steps | loss 0.22826 | ppl    1.256\n",
            "| epoch   5 |  1300/ 1600 steps | loss 0.05647 | ppl    1.058\n",
            "| epoch   5 |  1350/ 1600 steps | loss 0.05892 | ppl    1.061\n",
            "| epoch   5 |  1400/ 1600 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch   5 |  1450/ 1600 steps | loss 0.00470 | ppl    1.005\n",
            "| epoch   5 |  1500/ 1600 steps | loss 0.00007 | ppl    1.000\n",
            "| epoch   5 |  1550/ 1600 steps | loss 0.06094 | ppl    1.063\n",
            "from_scratch=False - VALIDATION ACCURACY 0.77\n",
            "| epoch   6 |    50/ 1600 steps | loss 0.01657 | ppl    1.017\n",
            "| epoch   6 |   100/ 1600 steps | loss 0.00009 | ppl    1.000\n",
            "| epoch   6 |   150/ 1600 steps | loss 0.17376 | ppl    1.190\n",
            "| epoch   6 |   200/ 1600 steps | loss 0.07458 | ppl    1.077\n",
            "| epoch   6 |   250/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch   6 |   300/ 1600 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch   6 |   350/ 1600 steps | loss 0.13943 | ppl    1.150\n",
            "| epoch   6 |   400/ 1600 steps | loss 0.22289 | ppl    1.250\n",
            "| epoch   6 |   450/ 1600 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch   6 |   500/ 1600 steps | loss 0.15033 | ppl    1.162\n",
            "| epoch   6 |   550/ 1600 steps | loss 0.01711 | ppl    1.017\n",
            "| epoch   6 |   600/ 1600 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch   6 |   650/ 1600 steps | loss 0.00286 | ppl    1.003\n",
            "| epoch   6 |   700/ 1600 steps | loss 0.00010 | ppl    1.000\n",
            "| epoch   6 |   750/ 1600 steps | loss 0.00007 | ppl    1.000\n",
            "| epoch   6 |   800/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch   6 |   850/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch   6 |   900/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch   6 |   950/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch   6 |  1000/ 1600 steps | loss 0.02126 | ppl    1.021\n",
            "| epoch   6 |  1050/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch   6 |  1100/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch   6 |  1150/ 1600 steps | loss 0.04196 | ppl    1.043\n",
            "| epoch   6 |  1200/ 1600 steps | loss 0.01483 | ppl    1.015\n",
            "| epoch   6 |  1250/ 1600 steps | loss 0.00002 | ppl    1.000\n",
            "| epoch   6 |  1300/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch   6 |  1350/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch   6 |  1400/ 1600 steps | loss 0.05338 | ppl    1.055\n",
            "| epoch   6 |  1450/ 1600 steps | loss 0.15891 | ppl    1.172\n",
            "| epoch   6 |  1500/ 1600 steps | loss 0.00454 | ppl    1.005\n",
            "| epoch   6 |  1550/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "from_scratch=False - VALIDATION ACCURACY 0.7665\n",
            "| epoch   7 |    50/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch   7 |   100/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch   7 |   150/ 1600 steps | loss 0.04464 | ppl    1.046\n",
            "| epoch   7 |   200/ 1600 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch   7 |   250/ 1600 steps | loss 0.31764 | ppl    1.374\n",
            "| epoch   7 |   300/ 1600 steps | loss 0.23244 | ppl    1.262\n",
            "| epoch   7 |   350/ 1600 steps | loss 0.00026 | ppl    1.000\n",
            "| epoch   7 |   400/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch   7 |   450/ 1600 steps | loss 0.00011 | ppl    1.000\n",
            "| epoch   7 |   500/ 1600 steps | loss 0.07822 | ppl    1.081\n",
            "| epoch   7 |   550/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch   7 |   600/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch   7 |   650/ 1600 steps | loss 0.08198 | ppl    1.085\n",
            "| epoch   7 |   700/ 1600 steps | loss 0.20165 | ppl    1.223\n",
            "| epoch   7 |   750/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch   7 |   800/ 1600 steps | loss 0.04312 | ppl    1.044\n",
            "| epoch   7 |   850/ 1600 steps | loss 0.00010 | ppl    1.000\n",
            "| epoch   7 |   900/ 1600 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch   7 |   950/ 1600 steps | loss 0.26433 | ppl    1.303\n",
            "| epoch   7 |  1000/ 1600 steps | loss 0.00002 | ppl    1.000\n",
            "| epoch   7 |  1050/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch   7 |  1100/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch   7 |  1150/ 1600 steps | loss 0.33538 | ppl    1.398\n",
            "| epoch   7 |  1200/ 1600 steps | loss 0.01412 | ppl    1.014\n",
            "| epoch   7 |  1250/ 1600 steps | loss 0.09708 | ppl    1.102\n",
            "| epoch   7 |  1300/ 1600 steps | loss 0.00074 | ppl    1.001\n",
            "| epoch   7 |  1350/ 1600 steps | loss 0.00121 | ppl    1.001\n",
            "| epoch   7 |  1400/ 1600 steps | loss 0.49960 | ppl    1.648\n",
            "| epoch   7 |  1450/ 1600 steps | loss 0.18030 | ppl    1.198\n",
            "| epoch   7 |  1500/ 1600 steps | loss 0.00553 | ppl    1.006\n",
            "| epoch   7 |  1550/ 1600 steps | loss 0.22017 | ppl    1.246\n",
            "from_scratch=False - VALIDATION ACCURACY 0.7875\n",
            "| epoch   8 |    50/ 1600 steps | loss 0.09966 | ppl    1.105\n",
            "| epoch   8 |   100/ 1600 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch   8 |   150/ 1600 steps | loss 0.00003 | ppl    1.000\n",
            "| epoch   8 |   200/ 1600 steps | loss 0.30866 | ppl    1.362\n",
            "| epoch   8 |   250/ 1600 steps | loss 0.40746 | ppl    1.503\n",
            "| epoch   8 |   300/ 1600 steps | loss 0.00005 | ppl    1.000\n",
            "| epoch   8 |   350/ 1600 steps | loss 0.01471 | ppl    1.015\n",
            "| epoch   8 |   400/ 1600 steps | loss 0.00047 | ppl    1.000\n",
            "| epoch   8 |   450/ 1600 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch   8 |   500/ 1600 steps | loss 0.27838 | ppl    1.321\n",
            "| epoch   8 |   550/ 1600 steps | loss 0.00142 | ppl    1.001\n",
            "| epoch   8 |   600/ 1600 steps | loss 0.50573 | ppl    1.658\n",
            "| epoch   8 |   650/ 1600 steps | loss 0.37768 | ppl    1.459\n",
            "| epoch   8 |   700/ 1600 steps | loss 0.21934 | ppl    1.245\n",
            "| epoch   8 |   750/ 1600 steps | loss 0.00002 | ppl    1.000\n",
            "| epoch   8 |   800/ 1600 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch   8 |   850/ 1600 steps | loss 0.00005 | ppl    1.000\n",
            "| epoch   8 |   900/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch   8 |   950/ 1600 steps | loss 0.13544 | ppl    1.145\n",
            "| epoch   8 |  1000/ 1600 steps | loss 0.23464 | ppl    1.264\n",
            "| epoch   8 |  1050/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch   8 |  1100/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch   8 |  1150/ 1600 steps | loss 0.08296 | ppl    1.086\n",
            "| epoch   8 |  1200/ 1600 steps | loss 0.27052 | ppl    1.311\n",
            "| epoch   8 |  1250/ 1600 steps | loss 0.00002 | ppl    1.000\n",
            "| epoch   8 |  1300/ 1600 steps | loss 0.00846 | ppl    1.008\n",
            "| epoch   8 |  1350/ 1600 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch   8 |  1400/ 1600 steps | loss 0.04196 | ppl    1.043\n",
            "| epoch   8 |  1450/ 1600 steps | loss 0.00020 | ppl    1.000\n",
            "| epoch   8 |  1500/ 1600 steps | loss 0.00012 | ppl    1.000\n",
            "| epoch   8 |  1550/ 1600 steps | loss 0.00004 | ppl    1.000\n",
            "from_scratch=False - VALIDATION ACCURACY 0.7775\n",
            "| epoch   9 |    50/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch   9 |   100/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch   9 |   150/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch   9 |   200/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch   9 |   250/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch   9 |   300/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch   9 |   350/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch   9 |   400/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch   9 |   450/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch   9 |   500/ 1600 steps | loss 0.00040 | ppl    1.000\n",
            "| epoch   9 |   550/ 1600 steps | loss 0.21102 | ppl    1.235\n",
            "| epoch   9 |   600/ 1600 steps | loss 0.00042 | ppl    1.000\n",
            "| epoch   9 |   650/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch   9 |   700/ 1600 steps | loss 0.75670 | ppl    2.131\n",
            "| epoch   9 |   750/ 1600 steps | loss 0.00002 | ppl    1.000\n",
            "| epoch   9 |   800/ 1600 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch   9 |   850/ 1600 steps | loss 0.00002 | ppl    1.000\n",
            "| epoch   9 |   900/ 1600 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch   9 |   950/ 1600 steps | loss 0.22817 | ppl    1.256\n",
            "| epoch   9 |  1000/ 1600 steps | loss 0.11687 | ppl    1.124\n",
            "| epoch   9 |  1050/ 1600 steps | loss 0.28666 | ppl    1.332\n",
            "| epoch   9 |  1100/ 1600 steps | loss 0.17185 | ppl    1.188\n",
            "| epoch   9 |  1150/ 1600 steps | loss 0.38518 | ppl    1.470\n",
            "| epoch   9 |  1200/ 1600 steps | loss 0.00002 | ppl    1.000\n",
            "| epoch   9 |  1250/ 1600 steps | loss 0.24016 | ppl    1.271\n",
            "| epoch   9 |  1300/ 1600 steps | loss 0.00005 | ppl    1.000\n",
            "| epoch   9 |  1350/ 1600 steps | loss 0.02175 | ppl    1.022\n",
            "| epoch   9 |  1400/ 1600 steps | loss 0.00026 | ppl    1.000\n",
            "| epoch   9 |  1450/ 1600 steps | loss 0.00066 | ppl    1.001\n",
            "| epoch   9 |  1500/ 1600 steps | loss 0.44257 | ppl    1.557\n",
            "| epoch   9 |  1550/ 1600 steps | loss 0.00038 | ppl    1.000\n",
            "from_scratch=False - VALIDATION ACCURACY 0.7765\n",
            "| epoch  10 |    50/ 1600 steps | loss 0.18406 | ppl    1.202\n",
            "| epoch  10 |   100/ 1600 steps | loss 0.00003 | ppl    1.000\n",
            "| epoch  10 |   150/ 1600 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  10 |   200/ 1600 steps | loss 0.13441 | ppl    1.144\n",
            "| epoch  10 |   250/ 1600 steps | loss 0.00013 | ppl    1.000\n",
            "| epoch  10 |   300/ 1600 steps | loss 0.05456 | ppl    1.056\n",
            "| epoch  10 |   350/ 1600 steps | loss 0.00007 | ppl    1.000\n",
            "| epoch  10 |   400/ 1600 steps | loss 0.00007 | ppl    1.000\n",
            "| epoch  10 |   450/ 1600 steps | loss 0.00014 | ppl    1.000\n",
            "| epoch  10 |   500/ 1600 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  10 |   550/ 1600 steps | loss 0.04690 | ppl    1.048\n",
            "| epoch  10 |   600/ 1600 steps | loss 0.22335 | ppl    1.250\n",
            "| epoch  10 |   650/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  10 |   700/ 1600 steps | loss 0.18742 | ppl    1.206\n",
            "| epoch  10 |   750/ 1600 steps | loss 0.29698 | ppl    1.346\n",
            "| epoch  10 |   800/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  10 |   850/ 1600 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  10 |   900/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  10 |   950/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  10 |  1000/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  10 |  1050/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  10 |  1100/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  10 |  1150/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  10 |  1200/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  10 |  1250/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  10 |  1300/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  10 |  1350/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  10 |  1400/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  10 |  1450/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  10 |  1500/ 1600 steps | loss 0.04847 | ppl    1.050\n",
            "| epoch  10 |  1550/ 1600 steps | loss 0.00000 | ppl    1.000\n",
            "from_scratch=False - VALIDATION ACCURACY 0.7975\n",
            "| epoch  11 |    50/ 1600 steps | loss 0.00002 | ppl    1.000\n"
          ]
        }
      ],
      "source": [
        "from_scratch_settings = [True, False]\n",
        "\n",
        "from_scratch_valid_acc = []\n",
        "pretrained_valid_acc = []\n",
        "lr = 0.0001\n",
        "\n",
        "for from_scratch in from_scratch_settings:\n",
        "    model_ds = Model(ntokens, nhead, nhid, nlayers, 2, dropout).to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model_ds.parameters(), lr=lr)\n",
        "    if not from_scratch:\n",
        "        print(\"=====PRETRAINED MODEL======\")\n",
        "        #load checkpoint\n",
        "        checkpoint = torch.load(\"pretrained_model_4layers_no_class_head.pt\")\n",
        "        #load state dict\n",
        "        model_ds.base.load_state_dict(checkpoint['model_state_dict'])\n",
        "    else:\n",
        "        print(\"=====Trainig FROM SCRATCH======\")\n",
        "    epochs = 15\n",
        "    # @TODO : freeze transformer weights!\n",
        "    # @TODO: check batch size subtlety on the last element (we want to classify the last feature of the sentence!)\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        train(\n",
        "            model_ds,\n",
        "            downstream_path_data_train,\n",
        "            downstream_path_labels_train,\n",
        "            save_interval=-1,\n",
        "            task=DS_TASK,\n",
        "            # batch_size=8,\n",
        "            batch_size=1, # TO AVOID THE NEED TO RETRIEVE THE RIGHT LAST TOKEN IN A BATCH\n",
        "            log_interval=50,\n",
        "            epoch=epoch,\n",
        "            name=\"_from_scratch\" if from_scratch else \"_pretrained\"\n",
        "        )\n",
        "        acc = evaluate_accuracy(\n",
        "            data_loader_validation,\n",
        "            model_ds\n",
        "        )\n",
        "        if from_scratch:\n",
        "            from_scratch_valid_acc.append(acc)\n",
        "        else:\n",
        "            pretrained_valid_acc.append(acc)\n",
        "        print(f\"{from_scratch=} - VALIDATION ACCURACY {acc}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "RCpBIdTHojm6"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#Visualize the accuracy\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(100.*np.array(from_scratch_valid_acc), \"-+r\", label=\"training from sratch\")\n",
        "plt.plot(100.*np.array(pretrained_valid_acc), \"-+b\", label=\"pretrained model\")\n",
        "plt.grid()\n",
        "plt.title(\"Classifier accuracy on a downstream task [Sentiment analyzis]\")\n",
        "plt.legend()\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy [%]\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.6.15 ('altegrad')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "1f3cfdeab8dd8f9900bd16266619de191cf0f5e09365d74b1fba1714dce58066"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
